{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Outline\n",
    "1. Import continental and assumed debt for each state\n",
    "2. Map towns to county names using mapping file + fuzzy string matching\n",
    "3. Use county shape files to create maps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Documentation Notes\n",
    "1. All non-exact matches will be printed out when doing merges (exact matches are not printed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning Questions\n",
    "1. What do we do about an entry that has entries for some debt types, but not for others? Do we want to drop those entries, impute the values, or set NA values to 0?\n",
    "2. What do we do about entries that have a state, but no town (ie: State of Connecticut)? What about no state?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def combineCols(df, num = 3):\n",
    "    change_df_agg = pd.DataFrame(columns = ['old', 'new', 'type'])\n",
    "    for col in ['town', 'state', 'occupation']:\n",
    "        # \" \".join(x.split()) removes all excess whitespace\n",
    "        # creates set with all unique instances of column\n",
    "        if num == 3:\n",
    "            df[col] = [set([\" \".join(x.split()) for x in [t1, t2, t3] if not pd.isnull(x)]) for t1, t2, t3 in zip(df[col+'1'],\n",
    "                                                                                                                  df[col+'2'],\n",
    "                                                                                                                  df[col+'3'])]\n",
    "        else:\n",
    "            df[col] = [set([\" \".join(x.split()) for x in [t1, t2] if not pd.isnull(x)]) for t1, t2 in zip(df[col+'1'],\n",
    "                                                                                                          df[col+'2'])]\n",
    "        if not any(df[col].apply(lambda x: len(x) > 1).tolist()):\n",
    "            # change set to string\n",
    "            print(\"reformatting {}\".format(col))\n",
    "            df[col] = df[col].apply(lambda x: x.pop() if x != set() else np.nan)\n",
    "        else:\n",
    "            print(\"{} column has multiple unique entries\".format(col))\n",
    "            print(\"see table at end for new entries\")\n",
    "            # keep the value that has the most characters, otherwise change set to string\n",
    "            old = df[df[col].apply(lambda x: len(x) > 1)][col]\n",
    "            df[col] = df[col].apply(lambda x: x.pop() if len(x) == 1 else np.nan if x == set() else max(list(x), key=len))\n",
    "            # new dataframe to keep track of changes\n",
    "            # create copy of change_df that removes all duplicates by turning old column, which is\n",
    "            # of type set to type string\n",
    "            change_df = pd.DataFrame([old, df.loc[old.index][col]]).T\n",
    "            change_df.columns = ['old', 'new']\n",
    "            change_df['type'] = col\n",
    "            change_df_str = change_df.copy()\n",
    "            change_df_str['old'] = change_df_str['old'].astype(str)\n",
    "            change_df_str = change_df_str.drop_duplicates()\n",
    "            # add filtered database of changes to aggregate dataset\n",
    "            change_df_agg = pd.concat([change_df_agg, change_df.loc[change_df_str.index]])\n",
    "\n",
    "    # add functions to combine asset totals, handle missing debt values\n",
    "\n",
    "    return df[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "               'town', 'state', 'occupation']], change_df_agg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "\"ind1, ind2, ind3 = CT_CD[['6p_Dollar', '6p_Cents']].dropna(thresh = 1).index,\\n                   CT_CD[['6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index,\\n                   CT_CD[['3p_Dollar', '3p_Cents']].dropna(thresh = 1).index\\nind = set(ind1).intersection(ind2).intersection(ind3)\""
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ind1, ind2, ind3 = CT_CD[['6p_Dollar', '6p_Cents']].dropna(thresh = 1).index,\n",
    "                   CT_CD[['6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index,\n",
    "                   CT_CD[['3p_Dollar', '3p_Cents']].dropna(thresh = 1).index\n",
    "ind = set(ind1).intersection(ind2).intersection(ind3)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Data\n",
    "1. Import CD and ASD for each state, combine the multiple town/state/occupation columns (if they exist) into one\n",
    "2. Concatenate all the separate datasets into two (one CD and one ASD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connecticut"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "CD_all = pd.DataFrame(columns = ['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                                  'town', 'state', 'occupation'])\n",
    "ASD_all = pd.DataFrame(columns = ['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                                  'town', 'state', 'occupation'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "town column has multiple unique entries\n",
      "see table at end for new entries\n",
      "reformatting state\n",
      "reformatting occupation\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   old      new  type\n526  {Milford, Miford}  Milford  town\n799  {Norwich, Nowich}  Norwich  town",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>old</th>\n      <th>new</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>526</th>\n      <td>{Milford, Miford}</td>\n      <td>Milford</td>\n      <td>town</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>{Norwich, Nowich}</td>\n      <td>Norwich</td>\n      <td>town</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing desired columns and rename\n",
    "CT_CD_raw = pd.read_excel(\"../../Data/Post1790/CT/CT_post1790_CD_ledger.xlsx\",\n",
    "                      header = 13, usecols = 'H, I, J, K, L, N, O, X, Y, Z, AA, AB, AD, AE, AN, AO, AP, AQ, AR, AT, AU')\n",
    "CT_CD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                     'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                     'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "# unify occupation, town and state columns\n",
    "CT_CD, change_df = combineCols(CT_CD_raw)\n",
    "CD_all = pd.concat([CD_all, CT_CD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "town column has multiple unique entries\n",
      "see table at end for new entries\n",
      "reformatting state\n",
      "occupation column has multiple unique entries\n",
      "see table at end for new entries\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   old  \\\n125                                 {Norwalk, Norwall}   \n811  {1st Society in Lyme, Treasuer 1st Society in ...   \n\n                              new        type  \n125                       Norwalk        town  \n811  Treasuer 1st Society in Lyme  occupation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>old</th>\n      <th>new</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>125</th>\n      <td>{Norwalk, Norwall}</td>\n      <td>Norwalk</td>\n      <td>town</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>{1st Society in Lyme, Treasuer 1st Society in ...</td>\n      <td>Treasuer 1st Society in Lyme</td>\n      <td>occupation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing desired columns and rename\n",
    "CT_ASD_raw = pd.read_excel(\"../../Data/Post1790/CT/CT_post1790_ASD_ledger.xlsx\",\n",
    "                       header = 13, usecols = 'H, I, J, K, L, N, O, X, Y, Z, AA, AB, AD, AE, AN, AO, AP, AQ, AR, AT, AU')\n",
    "CT_ASD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                     'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                     'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "# unify occupation, town and state columns\n",
    "CT_ASD, change_df = combineCols(CT_ASD_raw)\n",
    "ASD_all = pd.concat([ASD_all, CT_ASD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Georgia\n",
    "No need to do additional cleaning because there's only one state/city/occupation column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "# importing desired columns and rename\n",
    "# prepare loan dataset\n",
    "GA_CD_raw = pd.read_excel(\"../../Data/Post1790/GA/T694_GA_Loan_Office_CD.xlsx\",\n",
    "                      header = 10, usecols = 'Q, R, S, T, U, Z, AA, AB, AC, AD, AE')\n",
    "GA_CD_raw.columns = ['First Name', 'Last Name', 'town', 'state', 'occupation', '6p_Dollar', '6p_Cents',\n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "GA_CD = GA_CD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                   'town', 'state', 'occupation']]\n",
    "CD_all = pd.concat([CD_all, GA_CD])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Maryland"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reformatting town\n",
      "reformatting state\n",
      "reformatting occupation\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [old, new, type]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>old</th>\n      <th>new</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare loan dataset\n",
    "MD_CD_raw = pd.read_excel(\"../../Data/Post1790/MD/MD_post1790_CD.xlsx\",\n",
    "                      header = 11, usecols = 'G, H, I, J, K, L, M, U, V, W, X, Y, Z, AA, AI, AJ, AK, AL, AM, AN, AO')\n",
    "MD_CD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "# unify occupation, town and state columns\n",
    "MD_CD , change_df = combineCols(MD_CD_raw)\n",
    "CD_all = pd.concat([CD_all, MD_CD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reformatting town\n",
      "reformatting state\n",
      "reformatting occupation\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [old, new, type]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>old</th>\n      <th>new</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare loan dataset\n",
    "MD_ASD_raw = pd.read_excel(\"../../Data/Post1790/MD/MD_post1790_ASD.xlsx\",\n",
    "                      header = 11, usecols = 'G, H, I, J, K, L, M, U, V, W, X, Y, Z, AA, AI, AJ, AK, AL, AM, AN, AO')\n",
    "MD_ASD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "# unify occupation, town and state columns\n",
    "MD_ASD , change_df = combineCols(MD_ASD_raw)\n",
    "ASD_all = pd.concat([ASD_all, MD_ASD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### North Carolina"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "NC_CD_raw = pd.read_excel(\"../../Data/Post1790/NC/T695_R4_NC_CD.xlsx\",\n",
    "                      header = 11, usecols = 'J, K, L, M, N, W, X, Z, AA, AC, AD ')\n",
    "NC_CD_raw.columns = ['First Name', 'Last Name', 'town', 'state', 'occupation', '6p_Dollar', '6p_Cents',\n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_CD = NC_CD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                   'town', 'state', 'occupation']]\n",
    "CD_all = pd.concat([CD_all, NC_CD])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "NC_ASD_raw = pd.read_excel(\"../../Data/Post1790/NC/T695_R3_NC_ASD.xlsx\", header = 10, usecols = 'H, I, J, K, L, P, Q, R, S, T, U')\n",
    "NC_ASD_raw.columns = ['First Name', 'Last Name', 'town', 'state', 'occupation',  '6p_Dollar', '6p_Cents',\n",
    "                      '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_ASD = NC_ASD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                         'town', 'state', 'occupation']]\n",
    "ASD_all = pd.concat([ASD_all, NC_ASD])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### New Hampshire"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NH_CD_raw = pd.read_excel(\"../../Data/Post1790/NH/T652_R6_New_Hampshire_CD.xlsx\",\n",
    "                      header = 10, usecols = 'I, J, K, L, M, N, O, P, Q, R, S').drop([219, 220])\n",
    "NH_CD_raw.columns = ['First Name', 'Last Name', 'town', 'state', 'occupation', '6p_Dollar', '6p_Cents',\n",
    "                     '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NH_CD = NH_CD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                   'town', 'state', 'occupation']]\n",
    "CD_all = pd.concat([CD_all, NH_CD])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NH_ASD_raw = pd.read_excel(\"../../Data/Post1790/NH/T652_New_Hampshire_ASD.xlsx\", header = 12,\n",
    "                       usecols = 'G, H, I, J, K, M, N, V, W, X, Y, Z, AA, AB, AK, AL, AM, AN')\n",
    "NH_ASD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                      'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                      'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "# unify occupation, town and state columns\n",
    "NH_ASD, change_df = combineCols(NH_ASD_raw, 2)\n",
    "ASD_all = pd.concat([ASD_all, NH_ASD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### New York\n",
    "Doesn't have town/occupation/state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"#prepare loan dataset\n",
    "NY_CD_raw = pd.read_excel(\"../../Data/Post1790/NY/NY_1790_CD.xlsx\",\n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_CD_raw.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_CD_raw['state'] = np.nan\n",
    "NY_CD_raw['town'] = np.nan\n",
    "NY_CD_raw['occupation'] = np.nan\n",
    "NY_CD = NY_CD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                   'town', 'state', 'occupation']]\n",
    "CD_all = pd.concat([CD_all, NY_CD])\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"#prepare loan dataset\n",
    "NY_ASD_raw = pd.read_excel(\"../../Data/Post1790/NY/NY_1790_CD.xlsx\",\n",
    "                          header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_ASD_raw.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents',\n",
    "                     'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                     'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_ASD_raw['state'] = np.nan\n",
    "NY_ASD_raw['town'] = np.nan\n",
    "NY_ASD_raw['occupation'] = np.nan\n",
    "NY_ASD = NY_ASD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar', '3p_Cents',\n",
    "                   'town', 'state', 'occupation']]\n",
    "ASD_all = pd.concat([ASD_all, NY_ASD])\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pennsylvania"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "PA_CD_raw = pd.read_excel(\"../../Data/Post1790/PA/PA_post1790_CD.xlsx\",\n",
    "                      header = 11, usecols = 'G, H, I, J, K, L, M, U, V, W, X, Y, Z, AA, AJ, AK, AL, AM, AN, AO, AP')\n",
    "PA_CD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "# unify occupation, town and state columns\n",
    "PA_CD, change_df = combineCols(PA_CD_raw)\n",
    "CD_all = pd.concat([CD_all, PA_CD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rhode Island"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_CD_raw = pd.read_excel(\"../../Data/Post1790/RI/T653_Rhode_Island_CD.xlsx\",\n",
    "                      header = 11, usecols = 'G, H, I, J, K, L, M, U, V, W, X, Y, Z, AA, AI, AJ, AK, AL, AM, AN, AO')\n",
    "RI_CD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                     'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                     'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "RI_CD, change_df = combineCols(RI_CD_raw)\n",
    "CD_all = pd.concat([CD_all, RI_CD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_ASD_raw = pd.read_excel(\"../../Data/Post1790/RI/T653_Rhode_Island_ASD.xlsx\",\n",
    "                          header = 11, usecols = 'H, I, J, K, L, N, O, X, Y, Z, AA, AB, AD, AE, AN, AO, AP, AQ, AR, AT, AU')\n",
    "RI_ASD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                     'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                     'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "RI_ASD, change_df = combineCols(RI_ASD_raw)\n",
    "ASD_all = pd.concat([CD_all, RI_ASD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### South Carolina"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_CD_raw = pd.read_excel(\"../../Data/Post1790/SC/Post_1790_South_Carolina_CD.xlsx\",\n",
    "                      header = 11, usecols = 'D, E, F, G, H, M, N, S, T, U, V, W, AB, AC, AH, AI, AJ, AK, AL, AQ, AR')\n",
    "SC_CD_raw.columns = ['First Name', 'Last Name', 'town1', 'state1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', 'town2', 'state2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'town3', 'state3', 'occupation3', '3p_Dollar', '3p_Cents', ]\n",
    "SC_CD, change_df = combineCols(SC_CD_raw)\n",
    "CD_all = pd.concat([CD_all, SC_CD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_ASD_raw = pd.read_excel(\"../../Data/Post1790/SC/Post_1790_South_Carolina_ASD_transfers_removed.xlsx\", header = 11,\n",
    "                       usecols = 'D, E, F, G, H, M, N, O')\n",
    "SC_ASD_raw.columns = ['First Name', 'Last Name', 'town', 'state', 'occupation', '6p_Dollar', '6p_def_Dollar','3p_Dollar']\n",
    "for col in ['6p_', '6p_def_', '3p_']:\n",
    "    SC_ASD_raw[col+'Cents'] = SC_ASD_raw[col+'Dollar'] - np.round(SC_ASD_raw[col+'Dollar'], 0)\n",
    "    SC_ASD_raw[col+'Dollar'] = np.round(SC_ASD_raw['6p_Dollar'], 0)\n",
    "SC_ASD = SC_ASD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents',\n",
    "                     'town', 'state', 'occupation']]\n",
    "ASD_all = pd.concat([ASD_all, SC_ASD])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Virginia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#prepare loan dataset\n",
    "VA_CD_raw = pd.read_excel(\"../../Data/Post1790/VA/VA_CD.xlsx\",\n",
    "                      header = 11, usecols = 'H, I, K, L, U, V, X, Y, AH, AI, AK, AL')\n",
    "VA_CD_raw.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "VA_CD_raw['state'] = np.nan\n",
    "VA_CD_raw['town'] = np.nan\n",
    "VA_CD_raw['occupation'] = np.nan\n",
    "VA_CD = VA_CD_raw[['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents',\n",
    "                   'town', 'state', 'occupation']]\n",
    "CD_all = pd.concat([CD_all, VA_CD])\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "VA_ASD_raw = pd.read_excel(\"../../Data/Post1790/VA/VA_ASD.xlsx\", header = 11,\n",
    "                       usecols = 'D, E, F, G, N, O, U, V, W, X, AE, AF, AL, AM, AN, AO, AW, AX')\n",
    "VA_ASD_raw.columns = ['First Name', 'Last Name', 'town1', 'occupation1', '6p_Dollar', '6p_Cents',\n",
    "                  'First Name.1', 'Last Name.1', 'town2', 'occupation2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', 'town3', 'occupation3', '3p_Dollar', '3p_Cents']\n",
    "VA_ASD_raw['state1'] = np.nan\n",
    "VA_ASD_raw['state2'] = np.nan\n",
    "VA_ASD_raw['state3'] = np.nan\n",
    "VA_ASD, change_df = combineCols(VA_ASD_raw)\n",
    "ASD_all = pd.concat([ASD_all, VA_ASD])\n",
    "change_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ASD_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mapping Town/City to Counties - INCOMPLETE\n",
    "1. Connecticut: Referencing <a href = \"https://ctstatelibrary.org/cttowns/counties\">https://ctstatelibrary.org/cttowns/counties</a> I found that Huntington is now called Shelton and Chatham is now called East Hampton. The other two cases below are not mappable because those are not valid town names.\n",
    "2. Georgia: Investigate more, very few counties"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fuzzy string matching function\n",
    "def fuzzyMatch(unmatched_towns, towns, crosswalk, primary_dict, dict_matchcol = 'primary_city', initial = True, score_threshold = 85):\n",
    "    if initial:\n",
    "        print(\"\\nFuzzy City name - county matches\\n\")\n",
    "    else:\n",
    "        print(\"\\nFuzzy City name - county matches with string changes\\n\")\n",
    "    printedtowns = []\n",
    "    for town in unmatched_towns:\n",
    "        # extract best match\n",
    "        match_tuple = process.extractOne(town, [x for x in crosswalk[dict_matchcol] if not pd.isnull(x)])\n",
    "        score = match_tuple[1]\n",
    "        match = match_tuple[0]\n",
    "        # if match above threshold, change + print match so we can hand check\n",
    "        if score >= score_threshold:\n",
    "            if dict_matchcol == 'primary_city':\n",
    "                county = primary_dict[match]\n",
    "            if dict_matchcol == 'county':\n",
    "                county = match\n",
    "            # add match, print out match\n",
    "            if initial:\n",
    "                print(\"{} -> {} in {}\".format(town, match, county))\n",
    "                town_index = towns[towns['town'] == town].index\n",
    "                towns.loc[town_index, 'county'] = county\n",
    "            else:\n",
    "                original_town = towns[towns['town2'] == town]['town'].tolist()\n",
    "                if town not in printedtowns:\n",
    "                    print(\"{} (new name: {}) -> {} in {}\".format(original_town, town, match, county))\n",
    "                    printedtowns.append(town)\n",
    "                town_index = towns[towns['town'].apply(lambda x: x in original_town)].index\n",
    "                towns.loc[town_index, 'county'] = [county] * len(town_index)\n",
    "    return towns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def directTownMatch(state_cw, towns, col = 'primary_city', towncol = 'town'):\n",
    "    print(\"Direct City name - county matches\\n\")\n",
    "    # match towns directly based off crosswalk\n",
    "    primary_dict = dict(zip(state_cw[col],state_cw['county']))\n",
    "    if col == 'primary_city':\n",
    "        towns['county'] = towns[towncol].apply(lambda x: primary_dict.get(x, np.nan))\n",
    "    if col == 'acceptable_cities':\n",
    "        for ind in towns.index:\n",
    "            town = towns.loc[ind, 'town']\n",
    "            county = state_cw[state_cw[col].apply(lambda x: town in x if not pd.isnull(x) else False)]['county'].tolist()\n",
    "            if len(county)>0:\n",
    "                towns.loc[ind, 'county'] = county[0]\n",
    "    t = towns[towns['county'].apply(lambda x: not pd.isnull(x))]\n",
    "    if towncol == 'town':\n",
    "        for tn, cty in zip(t['town'], t['county']):\n",
    "            print(\"{} was matched to {} directly using the crosswalk\".format(tn, cty))\n",
    "    if towncol == 'town2':\n",
    "        for tn, tn_og, cty in zip(t['town2'], t['town'], t['county']):\n",
    "            print(\"{} (original: {}) was matched to {} directly using the crosswalk\".format(tn, tn_og, cty))\n",
    "    return primary_dict, towns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def directCountyMatch(state_cw, towns, towncol = 'town'):\n",
    "    print(\"\\nSome city names are actually county names\")\n",
    "    if towncol == 'town':\n",
    "        print(\"Direct City (county) name - county matches\\n\")\n",
    "    if towncol == 'town2':\n",
    "        print(\"Direct City (county) name with string changes - county matches\\n\")\n",
    "    # some own names are actually counties\n",
    "    # match towns based off whether town name is actually county name in crosswalk\n",
    "    counties = state_cw['county'].unique()\n",
    "    nanindex = towns[towns['county'].apply(lambda x: pd.isnull(x))].index\n",
    "    towns.loc[nanindex, 'county'] = towns.loc[nanindex, towncol].apply(lambda x: x if x in counties.tolist() else np.nan)\n",
    "    towns2 = towns.loc[nanindex]\n",
    "    nanindex2 = towns2[towns2['county'].apply(lambda x: not pd.isnull(x))].index\n",
    "    for t, c in zip(towns2.loc[nanindex2, towncol], towns2.loc[nanindex2, 'county']):\n",
    "        print(\"{} was matched to {} using the crosswalk\".format(t, c))\n",
    "    return towns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# change column of town dataframe's type to either town or county\n",
    "def addType(towns, type = 'town'):\n",
    "    towns['name_type'] = [name_type if not pd.isnull(name_type) else type if not pd.isnull(county) else np.nan for name_type, county in\n",
    "                          zip(towns['name_type'], towns['county'])]\n",
    "    return towns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "city_county_cw = pd.read_excel('../../Data/zip_code_database.xls')[['primary_city', 'acceptable_cities',\n",
    "                                                                    'unacceptable_cities', 'county', 'state']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_cw = pd.DataFrame(columns = ['town', 'county', 'state', 'name_type'])\n",
    "list_of_states = ['CT', 'GA', 'MD', 'NC', 'NH', 'NJ', 'PA', 'RI', 'SC',\n",
    "                  'MA', 'VA', 'DE']\n",
    "\n",
    "for state in list_of_states:\n",
    "    print(\"\\n{} MATCHING \\n\".format(state))\n",
    "    # create list of towns for each state\n",
    "    towns = CD_all[CD_all['state'] == state][['town']].drop_duplicates()\n",
    "    towns = towns[towns['town'].apply(lambda x: not pd.isnull(x))]\n",
    "    # state crosswalk\n",
    "    state_cw = city_county_cw[city_county_cw['state'] == state]\n",
    "    if state == 'VA':\n",
    "        state_cw = city_county_cw[city_county_cw['state'].apply(lambda x: x in ['VA', 'WV'])]\n",
    "    state_cw = state_cw[state_cw['county'].apply(lambda x: 'county' in x.lower() if not pd.isnull(x) else False)]\n",
    "    # try direct match: town name -> crosswalk town-county\n",
    "    oldtowns = towns.copy()\n",
    "    primary_dict, towns = directTownMatch(state_cw, towns, col = 'primary_city', towncol = 'town')\n",
    "    # label name type\n",
    "    towns['name_type'] = towns['county'].apply(lambda x: 'town' if not pd.isnull(x) else np.nan)\n",
    "\n",
    "    if state == 'CT':\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns1 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town']\n",
    "        towns = fuzzyMatch(unmatched_towns1, towns, state_cw, primary_dict, dict_matchcol = 'primary_city', initial = True, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "\n",
    "        # modify town names - towns changed names (see CT note)\n",
    "        # retry fuzzy match: town name -> crosswalk town-county\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('Huntington', 'Shelton').replace('Chatham', 'East Hampton'))\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "\n",
    "    if state == 'GA':\n",
    "        # some \"town\" names are actually counties\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        towns = directCountyMatch(state_cw, towns, towncol = 'town')\n",
    "        towns = addType(towns, 'county')\n",
    "    if state == 'MD':\n",
    "        # remove instances where Maryland is mentioned and unabbreviate county abbreviations\n",
    "        # use modified town names\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('Maryland', '').replace('Co ', 'County').strip())\n",
    "        towns = directCountyMatch(state_cw, towns, towncol = 'town2')\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol = 'county', initial = False, score_threshold = 86)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "\n",
    "\n",
    "        # correct a matching - Baltimore City to Baltimore County\n",
    "        print(\"Baltimore City changed to Baltimore County\")\n",
    "        towns['county'] = towns['county'].apply(lambda x: x.replace('City', 'County') if not pd.isnull(x) else x)\n",
    "        towns = addType(towns)\n",
    "    if state == 'NC':\n",
    "        # some \"town\" names are actually counties\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        towns = directCountyMatch(state_cw, towns, towncol = 'town')\n",
    "        towns = addType(towns, 'county')\n",
    "        # remove instances where North Carolina is mentioned and rename Tarborugh to enable matching\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('North Carolina', '').replace('Tarborugh', 'Tarboro').strip())\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "    if state == 'NH':\n",
    "        # use acceptable_cities instead of primary_cities column to match in the crosswalk\n",
    "        # try direct match: town name -> crosswalk town-county\n",
    "        null_ind = towns[towns['county'].apply(lambda x: pd.isnull(x))].index\n",
    "        pdict, tn = directTownMatch(state_cw, towns.loc[null_ind], col = 'acceptable_cities', towncol = 'town')\n",
    "        towns.loc[null_ind] = tn\n",
    "        towns = addType(towns)\n",
    "        # remove instances where New Hampshire and other geo-jurisdictional terms are used\n",
    "        # rename Rockingham to enable matching\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('State', '').replace('New Hampshire', '').replace('of ','').strip())\n",
    "        towns['town2'] = towns['town2'].apply(lambda x: x.replace('Rockingham', 'Rockingham County').strip())\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "        # some \"town\" names are actually counties\n",
    "        # use modified town names\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        towns = directCountyMatch(state_cw, towns, towncol = 'town2')\n",
    "        towns = addType(towns, 'county')\n",
    "        # manual fixes for matches\n",
    "        # manually adjust incorrect matches\n",
    "        print(\"\\nManual Match\\n\")\n",
    "        for town, county in zip(['Brintwood', 'Portsmouth New Hampshire'],\n",
    "                                ['Rockingham County', 'Portsmouth County']):\n",
    "            print(\"{} was matched to {}\".format(town, county))\n",
    "            if town == 'Brintwood':\n",
    "                towns.loc[towns[towns['town'] == town].index, ['county', 'name_type']] = [county,'town]']\n",
    "            else:\n",
    "                towns.loc[towns[towns['town'] == town].index, ['county', 'name_type']] = [county,'county']\n",
    "    if state == 'NJ':\n",
    "        # remove instances where New Jersey is used\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('New Jersey', '').strip())\n",
    "\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "        # some \"town\" names are actually counties\n",
    "        # use modified town names\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        towns = directCountyMatch(state_cw, towns, towncol = 'town2')\n",
    "        towns = addType(towns, 'county')\n",
    "    if state == 'PA':\n",
    "        # some \"town\" names are actually counties\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        towns = directCountyMatch(state_cw, towns, towncol = 'town')\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # use acceptable_cities instead of primary_cities column to match in the crosswalk\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        null_ind = towns[towns['county'].apply(lambda x: pd.isnull(x))].index\n",
    "        pdict, tn = directTownMatch(state_cw, towns.loc[null_ind], col = 'acceptable_cities', towncol = 'town')\n",
    "        towns.loc[null_ind] = tn\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # remove instances where New Jersey is used, fix some notational issues\n",
    "        # correct Dauphincoy to Dauphin and categorize Tulpehocken as being in Berks County\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('Co ', 'County').replace('Delaware', 'Delaware County').strip())\n",
    "        towns['town2'] = towns['town2'].apply(lambda x: x.replace('Pennsylvania', '').replace('County County','County').strip())\n",
    "        towns['town2'] = towns['town2'].apply(lambda x: x.replace('Country', 'County').replace('Dauphincoy','Dauphin').strip())\n",
    "        towns['town2'] = towns['town2'].apply(lambda x: x.replace('Tulpehocken', 'Berks County').strip())\n",
    "\n",
    "        # categorize different Philadelphia neighborhoods as belonging in Philadelphia\n",
    "        philreptowns = ['Blockley', 'Northan Liberties', 'Northern Liberties', \\\n",
    "                        'The Northern Libert', 'Passyunk', 'German Town', 'Southwark', 'Borden Town'] # not sure on this last one...\n",
    "        for town in philreptowns:\n",
    "            towns['town2'] = towns['town2'].apply(lambda x: x.replace(town, 'Philadelphia'))\n",
    "        towns = addType(towns)\n",
    "        # use modified town names\n",
    "        # try direct match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = directCountyMatch(state_cw, towns, 'town2')\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2_1 = [x for x in towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2'] if x != '']\n",
    "        towns = fuzzyMatch(unmatched_towns2_1, towns, state_cw, primary_dict, dict_matchcol = 'county', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # manually adjust incorrect matches\n",
    "        print(\"\\nManual Match\\n\")\n",
    "        for town, county in zip(['Charleston South Carolina', 'Burlington New Jersey', 'Northumberland County Virginia'],\n",
    "                                ['Charleston County', 'Philadelphia County', 'Northumberland County']):\n",
    "            print(\"{} was matched to {}\".format(town, county))\n",
    "            towns.loc[towns[towns['town'] == town].index, 'county'] = county\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "    if state == 'RI':\n",
    "        # remove instances where Rhode Island and other geo-jurisdictional terms are used\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('Rhode Island', '').replace('State ', '').replace('of', '').strip())\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town name -> crosswalk town-county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns)\n",
    "\n",
    "        # manually adjust incorrect matches\n",
    "        print(\"\\nManual Match\\n\")\n",
    "        for town, county in zip(['Gloucester', 'Richmond'],\n",
    "                                ['Providence County', 'Washington County']):\n",
    "            print(\"{} was matched to {}\".format(town, county))\n",
    "            towns.loc[towns[towns['town'] == town].index, 'county'] = county\n",
    "        towns = addType(towns)\n",
    "\n",
    "    if state == 'SC':\n",
    "        # remove instances where South Carolina is used, change number to character\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('South Carolina', '').replace('96', 'Ninety six').strip())\n",
    "\n",
    "        # use modified town names\n",
    "        # use acceptable_cities column\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        null_ind = towns[towns['county'].apply(lambda x: pd.isnull(x))].index\n",
    "        pdict, tn = directTownMatch(state_cw, towns.loc[null_ind], col = 'acceptable_cities', towncol = 'town2')\n",
    "        towns.loc[null_ind] = tn\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # some town names are actually county names\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2_1 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2_1, towns, state_cw, primary_dict, dict_matchcol ='county', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        townlist = ['St. Paul\\'s', 'Pee Dee', 'St. George', 'New River', 'Winyaw', 'Broad River', \\\n",
    "                    'Toogoodoo', 'St Pauls', 'Savannah', \\\n",
    "                    'James Island', 'St Andrews'] # last two are manual fixes\n",
    "        countylist = ['Clarendon County', 'Marion County', 'Dorchester County', 'Beaufort County', 'Winyah County', 'Beaufort County',\n",
    "                      'Charleston County', 'Clarendon County', 'Chatham Count', \\\n",
    "                      'Charleston County', 'Richland County']\n",
    "        for town, county in zip(townlist, countylist):\n",
    "            print(\"{} was matched to {}\".format(town, county))\n",
    "            towns.loc[towns[towns['town'] == town].index, 'county'] = county\n",
    "        towns = addType(towns)\n",
    "\n",
    "    if state == 'MA':\n",
    "        # remove instances where Massachusetts, MA or State is used\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('MA', '').replace('Massachusetts', '').replace('State','').strip())\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "    if state == 'VA':\n",
    "        # remove instances where Massachusetts, MA or State is used\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('VA', '').replace('Virginia', '').replace('Virgina','').strip())\n",
    "        towns['town2'] = towns['town2'].apply(lambda x: x.replace('State', '').replace(' of ', '').strip())\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # some town names are actually county names\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2_1 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2_1, towns, state_cw, primary_dict, dict_matchcol ='county', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        townlist = ['Portsmouth Virginia'] # last two are manual fixes\n",
    "        countylist = ['Norfolk County']\n",
    "        for town, county in zip(townlist, countylist):\n",
    "            print(\"{} was matched to {}\".format(town, county))\n",
    "            towns.loc[towns[towns['town'] == town].index, 'county'] = county\n",
    "        towns = addType(towns)\n",
    "    if state == 'DE':\n",
    "        # remove instances where Massachusetts, MA or State is used\n",
    "        towns['town2'] = towns['town'].apply(lambda x: x.replace('Delaware', '').replace('State', '').replace(' of ', '').strip())\n",
    "        towns['town2'] = towns['town2'].apply(lambda x: x.replace('Kent Company', 'Kent County').strip())\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2, towns, state_cw, primary_dict, dict_matchcol ='primary_city', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "        # some town names are actually county names\n",
    "        # use modified town names\n",
    "        # try fuzzy match: town (county) name -> crosswalk county\n",
    "        unmatched_towns2_1 = towns[towns['county'].apply(lambda x: pd.isnull(x))]['town2']\n",
    "        towns = fuzzyMatch(unmatched_towns2_1, towns, state_cw, primary_dict, dict_matchcol ='county', initial = False, score_threshold = 85)\n",
    "        towns = addType(towns, 'county')\n",
    "\n",
    "    # print out all unmatched names\n",
    "    print(\"\\nFinal Unmatched Names\\n\")\n",
    "    t = towns[towns['county'].apply(lambda x: pd.isnull(x))]\n",
    "    for tn in t['town']:\n",
    "        print(\"{} was unable to be matched\".format(tn))\n",
    "\n",
    "    towns = towns[towns['county'].apply(lambda x: not pd.isnull(x))]\n",
    "    towns['state'] = state\n",
    "    # only Georgia doesn't have a town2 column\n",
    "    if state not in ['GA']:\n",
    "        towns.drop('town2', axis = 1, inplace = True)\n",
    "\n",
    "    # correct states for certain counties/cities in PA and SC\n",
    "    if state == 'PA':\n",
    "        towns.loc[towns[towns['town'] == 'Charleston South Carolina'].index, 'state'] ='SC'\n",
    "        towns.loc[towns[towns['town'] == 'Northumberland County Virginia'].index, 'state'] = 'VA'\n",
    "    if state == 'SC':\n",
    "        towns.loc[towns[towns['town'] == 'Savannah'].index, 'state'] ='GA'\n",
    "\n",
    "\n",
    "    final_cw = pd.concat([final_cw, towns])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop duplicates that occur for some reason\n",
    "final_cw.drop_duplicates(subset = ['town', 'state'], inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add labels for county and name type to CD_all\n",
    "CD_all = pd.merge(CD_all, final_cw, on = ['town', 'state'], how = 'left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# manually input county, state and name type labels\n",
    "towns = ['Colchester', 'Charleston South Carolina', 'Philadelphia', 'Albany', 'Newark', 'Northumberland County Virginia', 'Savannah', 'City of New York', 'Long Island']\n",
    "counties = ['New London County', 'Berkeley County', 'Philadelphia County', 'Albany County', 'Essex County', 'Northumberland County', 'Chatham County', 'New York County', \\\n",
    "            np.nan]\n",
    "states = ['CT', 'SC', 'PA', 'NY', 'NJ', 'VA', 'GA', 'NY', 'NY']\n",
    "for town, county, state in zip(towns, counties, states):\n",
    "    if town == 'Northumberland County Virginia':\n",
    "        CD_all.loc[CD_all[CD_all['town'] == town].index, ['county', 'state', 'name_type']] = [county, state, 'county']\n",
    "    elif pd.isnull(county):\n",
    "        CD_all.loc[CD_all[CD_all['town'] == town].index, ['county', 'state', 'name_type']] = [county, state, 'other']\n",
    "    else:\n",
    "        CD_all.loc[CD_all[CD_all['town'] == town].index, ['county', 'state', 'name_type']] = [county, state, 'town']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# manually input county, state and name type labels\n",
    "colonies = ['New Hampshire', 'Massachusetts', 'Rhode Island', 'Connecticut', 'Conecticutt', 'New York', 'New Jersey', 'Pennsylvania', 'Delaware', 'Maryland', \\\n",
    "            'Virginia', 'North Carolina', 'South Carolina', 'Georgia', 'Vermont', 'Delawere']\n",
    "abbrev = ['NH', 'MA', 'RI', 'CT', 'CT', 'NY', 'NJ', 'PA', 'DE', 'MD', 'VA', 'NC', 'SC', 'GA', 'VT', 'DE']\n",
    "subsetted_CD_all = CD_all[CD_all['county'].apply(lambda x: pd.isnull(x))]\n",
    "for colony, abrv in zip(colonies, abbrev):\n",
    "    selind = subsetted_CD_all[subsetted_CD_all['town'].apply(lambda x: colony in x if not pd.isnull(x) else False)].index\n",
    "    CD_all.loc[selind, ['county', 'state', 'name_type']] = [np.nan, abrv, 'state']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CD_all[['town', 'state', 'county', 'name_type']].drop_duplicates().to_csv('../../Data/AssetGeography/countymapping.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CD_all['6p_total'] = CD_all['6p_Dollar'] + CD_all['6p_Cents']/100\n",
    "grouped_assets = CD_all.groupby(['county', 'state'])['6p_total'].sum()\n",
    "grouped_assets = grouped_assets.reset_index()\n",
    "grouped_assets.to_csv('../../Data/AssetGeography/county_debt_total.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
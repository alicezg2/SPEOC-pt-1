{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE1: there are several duplicate records.  \n",
    "NOTE2: one record (id: 537) has state CT but town is Vermont - possible that similar mistakes elsewhere.  \n",
    "NOTE3: how to distinguish town/county level - may need a list for reference if want to step further.  \n",
    "NOTE4: now need a manual check ('Haddam' =>'East Haddam')\n",
    "\n",
    "\n",
    "## Cleaning town names\n",
    "\n",
    "Goals:\n",
    "- Clean town names that are different but refer to the same town in `ASD_all.xlsx` and `CD_all.xlsx`.\n",
    "- check if all town names are in the \"town-county\" matching list given by `final_cw.xlsx` - if so, perform the matching.\n",
    "\n",
    "\n",
    "Step 1: flag by 1 records that have NA \"state\" and \"town\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5674, 9) (4337, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>532.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>508.00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>224.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>232.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>CT</td>\n",
       "      <td>Farmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>192.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>Farmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>172.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>814.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Chesterfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2030.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>954.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>477.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>715.00</td>\n",
       "      <td>82.0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Administrator of McKennie Sumner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>1342267.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>675291.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1026386.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5674 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents   3p_Dollar  3p_Cents  \\\n",
       "0        1064.00      75.0         532.00          37.0      508.00      51.0   \n",
       "1         449.00      96.0         224.00          97.0      232.00      10.0   \n",
       "2         154.00      20.0          77.00          10.0      192.00       NaN   \n",
       "3         196.00      75.0          98.00          37.0      172.00      24.0   \n",
       "4          53.00      58.0          26.00          79.0       67.00       6.0   \n",
       "...          ...       ...            ...           ...         ...       ...   \n",
       "5669         NaN       NaN            NaN           NaN      814.00       5.0   \n",
       "5670         NaN       NaN            NaN           NaN       28.00      29.0   \n",
       "5671         NaN       NaN            NaN           NaN     2030.00      35.0   \n",
       "5672      954.00      43.0         477.00          21.0      715.00      82.0   \n",
       "5673  1342267.46       NaN      675291.39           NaN  1026386.26       NaN   \n",
       "\n",
       "                town state                        occupation  \n",
       "0           Hartford    CT                          Merchant  \n",
       "1             Bolton    CT                            Farmer  \n",
       "2       Rhode Island    RI                            Farmer  \n",
       "3           Hartford    CT                          Merchant  \n",
       "4           Hartford    CT                          Merchant  \n",
       "...              ...   ...                               ...  \n",
       "5669    Chesterfield   NaN                               NaN  \n",
       "5670        Richmond   NaN                               NaN  \n",
       "5671        New York   NaN                               NaN  \n",
       "5672  North Carolina   NaN  Administrator of McKennie Sumner  \n",
       "5673             NaN   NaN                               NaN  \n",
       "\n",
       "[5674 rows x 9 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and cleaning\n",
    "ASD_all = pd.read_excel(\n",
    "    'ASD_all.xlsx', index_col=0).reset_index(drop=True).dropna(how='all').drop_duplicates().reset_index(drop=True)\n",
    "CD_all = pd.read_excel(\n",
    "    'CD_all.xlsx', index_col=0).reset_index(drop=True).dropna(how='all').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# strip white space\n",
    "for col in ['town', 'state', 'occupation']:\n",
    "    ASD_all[col] = ASD_all[col].str.strip()\n",
    "    CD_all[col] = CD_all[col].str.strip()\n",
    "    \n",
    "print(ASD_all.shape, CD_all.shape)\n",
    "\n",
    "ASD_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_all['FLAG'], CD_all['FLAG'] = 0, 0\n",
    "\n",
    "# identify NA rows\n",
    "ASD_all.loc[(pd.isna(ASD_all['town'])) | (pd.isna(ASD_all['state'])), 'FLAG'] = 1\n",
    "CD_all.loc[(pd.isna(CD_all['town'])) | (pd.isna(CD_all['state'])), 'FLAG'] = 1\n",
    "\n",
    "# select non-NA subdataframe\n",
    "ASD_no_NA = ASD_all[ASD_all['FLAG']==0]\n",
    "CD_no_NA = CD_all[CD_all['FLAG']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FC', 'DE', 'NJ', 'VI', 'RI', 'MD', 'MA', 'SC', 'FR', 'CT', 'BM', 'BVI', 'PA', 'US', 'NC', 'VT', 'NH', 'GB', 'NY', 'VA', 'GA'}\n"
     ]
    }
   ],
   "source": [
    "# check all states\n",
    "print(\n",
    "    set(list(ASD_no_NA.state.unique()) + list(CD_no_NA.state.unique()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: flag by 2 the records with states outside the following list of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>BVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>125.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>BVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>BVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>44482.0</td>\n",
       "      <td>-0.106667</td>\n",
       "      <td>44482.0</td>\n",
       "      <td>-0.053333</td>\n",
       "      <td>44482.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>London</td>\n",
       "      <td>GB</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>2346.0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>London</td>\n",
       "      <td>GB</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      6p_Dollar   6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \\\n",
       "1748       19.0        NaN            9.0      4.000000        NaN       NaN   \n",
       "1749      125.0  45.000000           62.0     73.000000      134.0     87.00   \n",
       "1750       90.0        NaN           45.0           NaN       93.0     84.00   \n",
       "4265    44482.0  -0.106667        44482.0     -0.053333    44482.0      0.42   \n",
       "4325     2346.0  -0.400000         2346.0     -0.200000     2346.0      0.20   \n",
       "\n",
       "          town state occupation  FLAG  \n",
       "1748  Eustatia   BVI        NaN   2.0  \n",
       "1749  Eustatia   BVI        NaN   2.0  \n",
       "1750  Eustatia   BVI        NaN   2.0  \n",
       "4265    London    GB   Merchant   2.0  \n",
       "4325    London    GB   Merchant   2.0  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list = ['RI', 'CT', 'GA', 'MD', 'NC', 'NH', 'NJ', 'NY', 'VA', 'PA', 'RI', 'SC', 'DE', 'MA', 'VT']\n",
    "state_name_list = [\n",
    "            'Rhode Island', 'Connecticut', 'Georgia', 'Maryland', 'North Carolina', \n",
    "            'New Hampshire', 'New Jersey', 'New York', 'Virginia',\n",
    "            'Pennsylvania', 'Rhode Island', 'South Carolina', 'Delaware', \n",
    "            'Massachusetts', 'Vermont'\n",
    "            ]\n",
    "state_list_dict = dict(zip(state_list, state_name_list))\n",
    "\n",
    "ASD_no_NA.loc[ASD_no_NA.apply(lambda row: row.state not in state_list, axis=1), 'FLAG'] = 2\n",
    "CD_no_NA.loc[CD_no_NA.apply(lambda row: row.state not in state_list, axis=1), 'FLAG'] = 2\n",
    "\n",
    "# update to the original df\n",
    "ASD_all.update(ASD_no_NA)\n",
    "CD_all.update(CD_no_NA)\n",
    "\n",
    "\n",
    "ASD_all[ASD_all['FLAG']==2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: flag by 3 the records\n",
    "- with town name 'State of XX' or 'State XX' or 'XX State' where XX is the state where the town is located, and \n",
    "- with town name exactly or almost the same as the state name (due to typos).\n",
    "\n",
    "These are records for which \"township\" is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>60.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>248.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State of New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>738.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>State of New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>State of Vermont</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \\\n",
       "2        154.0      20.0           77.0          10.0      192.0       NaN   \n",
       "35        60.0      37.0           30.0          18.0       63.0      83.0   \n",
       "102      248.0      46.0          124.0          23.0      144.0       NaN   \n",
       "122      738.0      43.0          369.0          22.0      708.0      13.0   \n",
       "167       30.0      48.0           15.0          24.0        8.0      22.0   \n",
       "\n",
       "                  town state occupation  FLAG  \n",
       "2         Rhode Island    RI     Farmer   3.0  \n",
       "35        Rhode Island    RI        NaN   3.0  \n",
       "102  State of New York    NY        NaN   3.0  \n",
       "122  State of New York    NY        NaN   3.0  \n",
       "167   State of Vermont    VT        NaN   3.0  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASD_rest = ASD_all[ASD_all['FLAG']==0]\n",
    "CD_rest = CD_all[CD_all['FLAG']==0]\n",
    "\n",
    "# state of XX/state XX - checked\n",
    "ASD_rest.loc[\n",
    "    ASD_rest.apply(lambda row: row.town.lower().startswith('state '), axis=1), 'FLAG'] = 3\n",
    "CD_rest.loc[\n",
    "    CD_rest.apply(lambda row: row.town.lower().startswith('state '), axis=1), 'FLAG'] = 3\n",
    "ASD_rest.loc[ASD_rest.town=='Delaware State', 'FLAG'] = 3\n",
    "CD_rest.loc[CD_rest.town=='Delaware State', 'FLAG'] = 3\n",
    "\n",
    "# town name == state name - checked\n",
    "ASD_rest.loc[ASD_rest.apply(lambda row: row.town==state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "CD_rest.loc[CD_rest.apply(lambda row: row.town==state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "\n",
    "# town name ~= state name - checked\n",
    "ASD_rest.loc[\n",
    "    ASD_rest.apply(lambda row: \n",
    "    process.cdist([row.town], [state_list_dict[row.state]])[0][0] >= 80, axis=1), 'FLAG'\n",
    "    ] = 3\n",
    "CD_rest.loc[\n",
    "    CD_rest.apply(lambda row: \n",
    "    process.cdist([row.town], [state_list_dict[row.state]])[0][0] >= 80, axis=1), 'FLAG'\n",
    "    ] = 3\n",
    "\n",
    "# Carolina in South Carolina (no county named Carolina)\n",
    "ASD_rest.loc[\n",
    "    ASD_rest.apply(lambda row: row.town in state_list_dict[row.state] and\n",
    "    row.town != state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "CD_rest.loc[\n",
    "    CD_rest.apply(lambda row: row.town in state_list_dict[row.state] and\n",
    "    row.town != state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "\n",
    "# update\n",
    "ASD_all.update(ASD_rest)\n",
    "CD_all.update(CD_rest)\n",
    "ASD_all[ASD_all['FLAG']==3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: unify town names\n",
    "- remove `\"state of\" + state_name` and `\"of\" + state_name` that appear in the town name, except \"City of New York\",\n",
    "- remove `\"state\" + state_name` that appears in the town name,\n",
    "- remove `state_name` from `XX + state_name` or `state_name + XX`,\n",
    "- take into account the three special cases.\n",
    "\n",
    "Then, \n",
    "- create a new identifier and remove \"Town\"/\"County\" from town names.\n",
    "\n",
    "Flag this change by 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_rest = ASD_all[ASD_all.FLAG==0]\n",
    "CD_rest = CD_all[CD_all.FLAG==0]\n",
    "\n",
    "def remove_state_from_town(row):\n",
    "    state_name = state_list_dict[row.state]\n",
    "    # state of/of\n",
    "    row.town = row.town.replace(' State of ' + state_name, '')\n",
    "    # state + state_name\n",
    "    row.town = row.town.replace(' State ' + state_name, '')\n",
    "    # special cases\n",
    "    if row.town == 'Boston state Massachusetts':\n",
    "        row.town = 'Boston'\n",
    "\n",
    "    if row.town == 'New Castle County Delaware State':\n",
    "        row.town = 'New Castle County'\n",
    "\n",
    "    if row.town == 'Virginia and Philadelphia':\n",
    "        row.town = 'Philadelphia'\n",
    "\n",
    "    if row.town != 'City of New York':\n",
    "        row.town = row.town.replace(' of ' + state_name, '')\n",
    "        row.town = row.town.replace(state_name, '')\n",
    "    \n",
    "    # flag changes\n",
    "    row.FLAG = 4\n",
    "    return row\n",
    "\n",
    "ASD_rest = ASD_rest.apply(lambda row: remove_state_from_town(row), axis=1)\n",
    "CD_rest = CD_rest.apply(lambda row: remove_state_from_town(row), axis=1)\n",
    "\n",
    "# town_level = 'T' if specified 'Town', 'C' if specified 'County', otherwise 'U'\n",
    "ASD_rest['town_level'] = 'U'\n",
    "ASD_rest.loc[ASD_rest['town'].str.contains('County', na=False), 'town_level'] = 'C'\n",
    "ASD_rest.loc[ASD_rest['town'].str.contains('Town', na=False), 'town_level'] = 'T'\n",
    "\n",
    "def remove_CountyTown(row):\n",
    "    row.town = row.town.replace('County', '')\n",
    "    row.town = row.town.replace('Town', '')\n",
    "    row.FLAG = 4\n",
    "    return row\n",
    "    \n",
    "ASD_rest = ASD_rest.apply(lambda row: remove_CountyTown(row), axis=1)\n",
    "CD_rest = CD_rest.apply(lambda row: remove_CountyTown(row), axis=1)\n",
    "\n",
    "\n",
    "ASD_all.update(ASD_rest)\n",
    "CD_all.update(CD_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: match town names that are likely to be the same one  \n",
    "1. for each state, create a list `A` of town names with # of occurences >= 4; create a list `B` for all the rest towns.\n",
    "2. for each town in list `B`, find the best three matches with towns in list `A` - if above a threshold, report all three and match to the best one. - to be checked afterwards\n",
    "3. all unmatched towns in list `B` become a new list `C` - we WANT to compare one another and if the similarity is above a threshold, group them; otherwise keep it untouched. One simple procedure is for each town in list `C`, group it with all other towns whose distance to it is smaller than a threshold. Then proceed to the next one if it's not in some group already and skip otherwise. This is legitimate because we expect \"typos\" to cause small differences among all mistyped names. Report all the matched and unmatched cases in this round.\n",
    "4. For all above, allow user's input to manually confirm the matches.\n",
    "\n",
    "Flag this change by 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_towns(df):\n",
    "    if len(df.index)==0:    # Vermont\n",
    "        return df\n",
    "    print(f\"State: {df.state.iloc[0]}\")\n",
    "\n",
    "    val_counts = df.town.value_counts(sort=True)\n",
    "    list_A, list_B = list(val_counts[val_counts>=min(val_counts.iloc[0], 4)].index), list(val_counts[val_counts<min(val_counts.iloc[0], 4)].index)\n",
    "    list_C = list_B.copy()\n",
    "    for town in list_B:\n",
    "        best3 = process.extract(town, list_A)[0:3]\n",
    "        if best3[0][1] >= 85:\n",
    "            print(f\"{town}. Candidates: {[x[0] for x in best3]}. Matched: {best3[0][0]}.\\n\")\n",
    "\n",
    "            # # user input\n",
    "            # ACCEPT = input(\"1 for ACCEPT. 0 for REJECT\")\n",
    "            # # records\n",
    "\n",
    "            # if ACCEPT==1:\n",
    "            # matched to list_A\n",
    "            list_C.remove(town)\n",
    "            df.loc[df.town==town, 'FLAG'] = 5\n",
    "            df.loc[df.town==town, 'town'] = best3[0][0]\n",
    "\n",
    "    list_C_flag = [-1 for x in list_C]\n",
    "    for id, town in enumerate(list_C):\n",
    "        # only do matching if not already matched\n",
    "        if list_C_flag[id] == -1:\n",
    "            bests = [x[0] for x in process.extract(town, list_C, score_cutoff=85)]\n",
    "            if len(bests) > 1:\n",
    "                # if not just oneself\n",
    "                indexes = [list_C.index(x) for x in bests]\n",
    "                # make sure same group has the same id\n",
    "                print(f\"Candidate group: {bests}\")\n",
    "                for k in indexes: \n",
    "                    list_C_flag[k] = id \n",
    "    \n",
    "    for id, flag in enumerate(list_C_flag):\n",
    "        if flag != -1:\n",
    "            df.loc[df.town==list_C[id], 'FLAG'] = 5\n",
    "            df.loc[df.town==list_C[id], 'town'] = list_C[flag]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: RI\n",
      "Conventry. Candidates: ['Coventry', 'Exeter', 'North Providence']. Matched: Coventry.\n",
      "\n",
      "Glocester. Candidates: ['Gloucester', 'Exeter', 'Coventry']. Matched: Gloucester.\n",
      "\n",
      "North Kingstone. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "North Kingstown. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Stoughton now of Providence. Candidates: ['Providence', 'North Providence', 'Johnston']. Matched: Providence.\n",
      "\n",
      "Smithfeild. Candidates: ['Smithfield', 'Scituate', 'Cumberland']. Matched: Smithfield.\n",
      "\n",
      "South Kingstone. Candidates: ['South Kingston', 'North Kingston', 'Johnston']. Matched: South Kingston.\n",
      "\n",
      "Warnick. Candidates: ['Warwick', 'Warren', 'East Greenwich']. Matched: Warwick.\n",
      "\n",
      "State: RI\n",
      "North Kingstown. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Stoughton now of Providence. Candidates: ['Providence', 'North Providence', 'Johnston']. Matched: Providence.\n",
      "\n",
      "South Kingstone. Candidates: ['South Kingston', 'North Kingston', 'Johnston']. Matched: South Kingston.\n",
      "\n",
      "North Kingstone. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Smithfeild. Candidates: ['Smithfield', 'Scituate', 'North Providence']. Matched: Smithfield.\n",
      "\n",
      "State: CT\n",
      "Haddam. Candidates: ['East Haddam', 'Chatham', 'Windham']. Matched: East Haddam.\n",
      "\n",
      "Stonnington. Candidates: ['Stonington', 'Torrington', 'Groton']. Matched: Stonington.\n",
      "\n",
      "Stafford. Candidates: ['Stamford', 'Stratford', 'East Hartford']. Matched: Stamford.\n",
      "\n",
      "New Hartford. Candidates: ['Hartford', 'East Hartford', 'New Milford']. Matched: Hartford.\n",
      "\n",
      "Middletown . Candidates: ['Middletown', 'Bolton', 'Groton']. Matched: Middletown.\n",
      "\n",
      "Colchestert. Candidates: ['Colchester', 'Coventry', 'Norwich']. Matched: Colchester.\n",
      "\n",
      "London. Candidates: ['New London', 'Lebanon', 'Bolton']. Matched: New London.\n",
      "\n",
      "Wethersfield in t. Candidates: ['Wethersfield', 'Suffield', 'Mansfield']. Matched: Wethersfield.\n",
      "\n",
      "Candidate group: ['Cornwall', 'Cornwell']\n",
      "Candidate group: ['Brooklyn', 'Brooklyne']\n",
      "Candidate group: ['Volentown', 'Voluntown']\n",
      "Candidate group: ['Southhampton', 'Hampton']\n",
      "Candidate group: ['Northampton', 'Hampton']\n",
      "State: CT\n",
      "Stonnington. Candidates: ['Stonington', 'Torrington', 'Groton']. Matched: Stonington.\n",
      "\n",
      "Haddam. Candidates: ['East Haddam', 'Chatham', 'Windham']. Matched: East Haddam.\n",
      "\n",
      "Stafford. Candidates: ['Stamford', 'Stratford', 'East Hartford']. Matched: Stamford.\n",
      "\n",
      "New Hartford. Candidates: ['Hartford', 'East Hartford', 'New Milford']. Matched: Hartford.\n",
      "\n",
      "London. Candidates: ['New London', 'Lebanon', 'Bolton']. Matched: New London.\n",
      "\n",
      "Candidate group: ['Cornwall', 'Cornwell']\n",
      "Candidate group: ['Brooklyn', 'Brooklyne']\n",
      "Candidate group: ['Volentown', 'Voluntown']\n",
      "Candidate group: ['Hampton', 'Southhampton', 'Northampton']\n",
      "State: GA\n",
      "State: GA\n",
      "State: MD\n",
      "Montgomery  . Candidates: ['Montgomery ', 'George ', 'St Marys ']. Matched: Montgomery .\n",
      "\n",
      "Frederick  . Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "George town. Candidates: ['George ', 'Prince Georges ', 'Somerset ']. Matched: George .\n",
      "\n",
      "Frederick. Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "Georges . Candidates: ['George ', 'Prince Georges ', 'Dorchester ']. Matched: George .\n",
      "\n",
      "Somerset  . Candidates: ['Somerset ', 'St Marys ', 'Montgomery ']. Matched: Somerset .\n",
      "\n",
      "Candidate group: ['Talbot ', 'Talbot']\n",
      "Candidate group: ['Calvert ', 'Calver ']\n",
      "State: MD\n",
      "Montgomery  . Candidates: ['Montgomery ', 'George ', 'St Marys ']. Matched: Montgomery .\n",
      "\n",
      "Frederick  . Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "George town. Candidates: ['George ', 'Prince Georges ', 'Somerset ']. Matched: George .\n",
      "\n",
      "Frederick. Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "Georges . Candidates: ['George ', 'Prince Georges ', 'Dorchester ']. Matched: George .\n",
      "\n",
      "Somerset  . Candidates: ['Somerset ', 'St Marys ', 'Montgomery ']. Matched: Somerset .\n",
      "\n",
      "Candidate group: ['Talbot ', 'Talbot']\n",
      "Candidate group: ['Calvert ', 'Calver ']\n",
      "State: NC\n",
      "State: NC\n",
      "State: NH\n",
      "Portsmouth . Candidates: ['Portsmouth', 'Concord', 'Exeter']. Matched: Portsmouth.\n",
      "\n",
      "Candidate group: ['South Hampton', 'Hampton']\n",
      "Candidate group: ['Londonberry', 'London']\n",
      "Candidate group: ['Charleston', 'Charlestown']\n",
      "Candidate group: ['North Hampton', 'Hampton']\n",
      "Candidate group: ['Newport in ', 'Newport ']\n",
      "State: NH\n",
      "Portsmouth . Candidates: ['Portsmouth', 'Concord', 'Exeter']. Matched: Portsmouth.\n",
      "\n",
      "Candidate group: ['South Hampton', 'Hampton']\n",
      "Candidate group: ['Charleston', 'Charlestown']\n",
      "Candidate group: ['Londonberry', 'London']\n",
      "Candidate group: ['North Hampton', 'Hampton']\n",
      "State: NJ\n",
      "Candidate group: ['Brunswick ', 'New Brunswick ']\n",
      "Candidate group: ['Cape May ', 'Cape May']\n",
      "State: NJ\n",
      "Candidate group: ['Brunswick ', 'New Brunswick ']\n",
      "Candidate group: ['Cape May ', 'Cape May']\n",
      "State: NY\n",
      "State: NY\n",
      "State: VA\n",
      "Candidate group: ['Alexandria', 'Alexandria ']\n",
      "State: VA\n",
      "Candidate group: ['Alexandria', 'Alexandria ']\n",
      "State: PA\n",
      "Chester  Pennsylvaina. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Franklin . Candidates: ['Franklin  ', 'Reading', 'Reading ']. Matched: Franklin  .\n",
      "\n",
      "Philadephia. Candidates: ['Philadelphia', 'Philadelphia ', 'Bethlehem']. Matched: Philadelphia.\n",
      "\n",
      " Berks . Candidates: ['Berks  ', 'Berks ', 'Reading Berks ']. Matched: Berks  .\n",
      "\n",
      "Chester Co . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Hatter Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      " of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Bethlehem']. Matched: Philadelphia.\n",
      "\n",
      "Montgomery  . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Northumberland  . Candidates: ['Northumberland ', 'Berks  ', 'Berks ']. Matched: Northumberland .\n",
      "\n",
      "Church on Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      "Philadelphila. Candidates: ['Philadelphia', 'Philadelphia ', 'Carlisle ']. Matched: Philadelphia.\n",
      "\n",
      "Northumberland  Virginia. Candidates: ['Northumberland ', 'Northern Liberties', 'Berks  ']. Matched: Northumberland .\n",
      "\n",
      "German . Candidates: ['Germantown', 'Northumberland ', 'Northern Liberties']. Matched: Germantown.\n",
      "\n",
      "Northan Liberties. Candidates: ['Northern Liberties', 'Franklin  ', 'Berks  ']. Matched: Northern Liberties.\n",
      "\n",
      " Montgomery . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "The N Lib of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Northern Liberties']. Matched: Philadelphia.\n",
      "\n",
      "Montgomery. Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Frankford Philadelphia . Candidates: ['Philadelphia', 'Philadelphia ', 'Franklin  ']. Matched: Philadelphia.\n",
      "\n",
      "Chester. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Chester and . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Northum  . Candidates: ['Northumberland ', 'Northern Liberties', 'York  ']. Matched: Northumberland .\n",
      "\n",
      "Candidate group: ['Westmoreland ', 'Westmoreland  ', 'Westmoreland']\n",
      "Candidate group: ['Dauphin ', 'Dauphin  ', 'Dauphin and Company', 'Paxton Tot Dauphin ']\n",
      "Candidate group: ['Northampton  ', 'Northampton ']\n",
      "Candidate group: ['Pittsburgh ', 'Pittsburgh']\n",
      "Candidate group: ['Delaware', 'Delaware ', 'Delaware  ']\n",
      "Candidate group: ['Allegheny  ', 'Allegheny ']\n",
      "Candidate group: ['Kensington', 'Kensignton']\n",
      "Candidate group: ['Cumberland', 'Cumb  ']\n",
      "State: PA\n",
      "Chester  Pennsylvaina. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Franklin . Candidates: ['Franklin  ', 'Reading', 'Reading ']. Matched: Franklin  .\n",
      "\n",
      " Berks . Candidates: ['Berks  ', 'Berks ', 'Reading Berks ']. Matched: Berks  .\n",
      "\n",
      "Chester Co . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Montgomery  . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Hatter Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      "German . Candidates: ['Germantown', 'Northumberland ', 'Northern Liberties']. Matched: Germantown.\n",
      "\n",
      "Philadelphila. Candidates: ['Philadelphia', 'Philadelphia ', 'Carlisle ']. Matched: Philadelphia.\n",
      "\n",
      "Northumberland  Virginia. Candidates: ['Northumberland ', 'Northern Liberties', 'Berks  ']. Matched: Northumberland .\n",
      "\n",
      "Church on Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      "Northumberland  . Candidates: ['Northumberland ', 'Berks  ', 'Berks ']. Matched: Northumberland .\n",
      "\n",
      "Chester and . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Northum  . Candidates: ['Northumberland ', 'Northern Liberties', 'York  ']. Matched: Northumberland .\n",
      "\n",
      "Chester. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      " of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Bethlehem']. Matched: Philadelphia.\n",
      "\n",
      "Northan Liberties. Candidates: ['Northern Liberties', 'Franklin  ', 'Berks  ']. Matched: Northern Liberties.\n",
      "\n",
      "Montgomery. Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "The N Lib of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Northern Liberties']. Matched: Philadelphia.\n",
      "\n",
      " Montgomery . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Frankford Philadelphia . Candidates: ['Philadelphia', 'Philadelphia ', 'Franklin  ']. Matched: Philadelphia.\n",
      "\n",
      "Candidate group: ['Northampton  ', 'Northampton ']\n",
      "Candidate group: ['Dauphin ', 'Dauphin  ', 'Dauphin and Company', 'Paxton Tot Dauphin ']\n",
      "Candidate group: ['Westmoreland ', 'Westmoreland  ', 'Westmoreland']\n",
      "Candidate group: ['Pittsburgh ', 'Pittsburgh']\n",
      "Candidate group: ['Allegheny  ', 'Allegheny ']\n",
      "Candidate group: ['Delaware', 'Delaware ', 'Delaware  ']\n",
      "Candidate group: ['Kensington', 'Kensignton']\n",
      "Candidate group: ['Cumberland', 'Cumb  ']\n",
      "State: RI\n",
      "State: RI\n",
      "State: SC\n",
      "Charleston  . Candidates: ['Charleston', 'Charleston ', 'Santee']. Matched: Charleston.\n",
      "\n",
      "St James Santee. Candidates: ['Santee', 'St Eustatius', 'Charleston']. Matched: Santee.\n",
      "\n",
      "St Lukes. Candidates: ['St Eustatius', 'Santee', 'Charleston']. Matched: St Eustatius.\n",
      "\n",
      "St James Parish Santee. Candidates: ['Santee', 'St Eustatius', 'Charleston']. Matched: Santee.\n",
      "\n",
      "St George's Parish. Candidates: ['St Eustatius', 'Santee', 'Charleston']. Matched: St Eustatius.\n",
      "\n",
      "Candidate group: ['Camden', 'Camden District']\n",
      "Candidate group: [\"St Bartholomew's\", \"St Luke's\", 'St Helena', \"Bartholomew's Parish\"]\n",
      "Candidate group: [\"St John's Parish\", \"St Johnn's Parish\", \"St Luke's\", 'St Helena']\n",
      "Candidate group: ['St Gustavus', \"St Johnn's Parish\"]\n",
      "Candidate group: [\"John's Island\", \"Bartholomew's Parish\"]\n",
      "State: SC\n",
      "Charleston  . Candidates: ['Charleston', 'Charleston ', 'Georgetown']. Matched: Charleston.\n",
      "\n",
      "Charlestom. Candidates: ['Charleston', 'Charleston ', 'Camden']. Matched: Charleston.\n",
      "\n",
      "Camden Planter. Candidates: ['Camden', 'James Island', 'Charleston']. Matched: Camden.\n",
      "\n",
      "Candidate group: ['Ninety six District', '96 District']\n",
      "Candidate group: ['St Pauls', \"St. Paul's\"]\n",
      "Candidate group: ['Richard ', 'Richard Sennings']\n",
      "State: DE\n",
      " Newcastle . Candidates: ['New Castle ']. Matched: New Castle .\n",
      "\n",
      "State: DE\n",
      " Newcastle . Candidates: ['New Castle ']. Matched: New Castle .\n",
      "\n",
      "State: MA\n",
      "Cambridge . Candidates: ['Cambridge', 'Springfield', 'Attleborough']. Matched: Cambridge.\n",
      "\n",
      "Candidate group: ['Grafton', 'Grafton ']\n",
      "Candidate group: ['Tyringham MA', 'Tyringham ']\n",
      "State: MA\n",
      "Candidate group: ['Cambridge', 'Cambridge ']\n",
      "Candidate group: ['Tyringham MA', 'Tyringham ']\n"
     ]
    }
   ],
   "source": [
    "for state_code in state_list:\n",
    "    \n",
    "    ASD_rest[ASD_rest.state==state_code] = match_towns(ASD_rest[ASD_rest.state==state_code])\n",
    "    CD_rest[CD_rest.state==state_code] = match_towns(CD_rest[CD_rest.state==state_code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
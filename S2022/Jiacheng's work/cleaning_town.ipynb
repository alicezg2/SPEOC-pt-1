{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE1: there are several duplicate records.  \n",
    "NOTE2: one record (id: 537) has state CT but town is Vermont - possible that similar mistakes elsewhere.  \n",
    "NOTE3: how to distinguish town/county level - may need a list for reference if want to step further.  \n",
    "NOTE4: now need a manual check ('Haddam' =>'East Haddam')\n",
    "\n",
    "\n",
    "## Cleaning town names\n",
    "\n",
    "Goals:\n",
    "- Clean town names that are different but refer to the same town in `ASD_all.xlsx` and `CD_all.xlsx`.\n",
    "- check if all town names are in the \"town-county\" matching list given by `final_cw.xlsx` - if so, perform the matching.\n",
    "\n",
    "\n",
    "Step 1: flag by 1 records that have NA \"state\" and \"town\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5674, 10) (4337, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>orig_town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>532.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>508.00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Hartford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>224.00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>232.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>CT</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>Bolton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>192.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>172.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Hartford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Hartford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>814.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Chesterfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chesterfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Richmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2030.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>954.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>477.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>715.00</td>\n",
       "      <td>82.0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Administrator of McKennie Sumner</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>1342267.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>675291.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1026386.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5674 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents   3p_Dollar  3p_Cents  \\\n",
       "0        1064.00      75.0         532.00          37.0      508.00      51.0   \n",
       "1         449.00      96.0         224.00          97.0      232.00      10.0   \n",
       "2         154.00      20.0          77.00          10.0      192.00       NaN   \n",
       "3         196.00      75.0          98.00          37.0      172.00      24.0   \n",
       "4          53.00      58.0          26.00          79.0       67.00       6.0   \n",
       "...          ...       ...            ...           ...         ...       ...   \n",
       "5669         NaN       NaN            NaN           NaN      814.00       5.0   \n",
       "5670         NaN       NaN            NaN           NaN       28.00      29.0   \n",
       "5671         NaN       NaN            NaN           NaN     2030.00      35.0   \n",
       "5672      954.00      43.0         477.00          21.0      715.00      82.0   \n",
       "5673  1342267.46       NaN      675291.39           NaN  1026386.26       NaN   \n",
       "\n",
       "                town state                        occupation       orig_town  \n",
       "0           Hartford    CT                          Merchant        Hartford  \n",
       "1             Bolton    CT                            Farmer          Bolton  \n",
       "2       Rhode Island    RI                            Farmer    Rhode Island  \n",
       "3           Hartford    CT                          Merchant        Hartford  \n",
       "4           Hartford    CT                          Merchant        Hartford  \n",
       "...              ...   ...                               ...             ...  \n",
       "5669    Chesterfield   NaN                               NaN    Chesterfield  \n",
       "5670        Richmond   NaN                               NaN        Richmond  \n",
       "5671        New York   NaN                               NaN        New York  \n",
       "5672  North Carolina   NaN  Administrator of McKennie Sumner  North Carolina  \n",
       "5673             NaN   NaN                               NaN             NaN  \n",
       "\n",
       "[5674 rows x 10 columns]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and cleaning\n",
    "ASD_all = pd.read_excel(\n",
    "    'ASD_all.xlsx', index_col=0).reset_index(drop=True).dropna(how='all').drop_duplicates().reset_index(drop=True)\n",
    "CD_all = pd.read_excel(\n",
    "    'CD_all.xlsx', index_col=0).reset_index(drop=True).dropna(how='all').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# strip white space\n",
    "for col in ['town', 'state', 'occupation']:\n",
    "    ASD_all[col] = ASD_all[col].str.strip()\n",
    "    CD_all[col] = CD_all[col].str.strip()\n",
    "\n",
    "ASD_all['orig_town'] = ASD_all['town']\n",
    "CD_all['orig_town'] = CD_all['town']\n",
    "    \n",
    "print(ASD_all.shape, CD_all.shape)\n",
    "\n",
    "ASD_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_all['FLAG'], CD_all['FLAG'] = 0, 0\n",
    "\n",
    "# identify NA rows\n",
    "ASD_all.loc[(pd.isna(ASD_all['town'])) | (pd.isna(ASD_all['state'])), 'FLAG'] = 1\n",
    "CD_all.loc[(pd.isna(CD_all['town'])) | (pd.isna(CD_all['state'])), 'FLAG'] = 1\n",
    "\n",
    "# select non-NA subdataframe\n",
    "ASD_no_NA = ASD_all[ASD_all['FLAG']==0]\n",
    "CD_no_NA = CD_all[CD_all['FLAG']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NJ', 'VA', 'DE', 'MD', 'NY', 'PA', 'GB', 'VT', 'US', 'GA', 'VI', 'BVI', 'FR', 'FC', 'SC', 'MA', 'BM', 'RI', 'NC', 'NH', 'CT'}\n"
     ]
    }
   ],
   "source": [
    "# check all states\n",
    "print(\n",
    "    set(list(ASD_no_NA.state.unique()) + list(CD_no_NA.state.unique()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: flag by 2 the records with states outside the following list of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>orig_town</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>BVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>125.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>BVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>BVI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eustatia</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>44482.0</td>\n",
       "      <td>-0.106667</td>\n",
       "      <td>44482.0</td>\n",
       "      <td>-0.053333</td>\n",
       "      <td>44482.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>London</td>\n",
       "      <td>GB</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>London</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>2346.0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>London</td>\n",
       "      <td>GB</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>London</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      6p_Dollar   6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \\\n",
       "1748       19.0        NaN            9.0      4.000000        NaN       NaN   \n",
       "1749      125.0  45.000000           62.0     73.000000      134.0     87.00   \n",
       "1750       90.0        NaN           45.0           NaN       93.0     84.00   \n",
       "4265    44482.0  -0.106667        44482.0     -0.053333    44482.0      0.42   \n",
       "4325     2346.0  -0.400000         2346.0     -0.200000     2346.0      0.20   \n",
       "\n",
       "          town state occupation orig_town  FLAG  \n",
       "1748  Eustatia   BVI        NaN  Eustatia   2.0  \n",
       "1749  Eustatia   BVI        NaN  Eustatia   2.0  \n",
       "1750  Eustatia   BVI        NaN  Eustatia   2.0  \n",
       "4265    London    GB   Merchant    London   2.0  \n",
       "4325    London    GB   Merchant    London   2.0  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_list = ['RI', 'CT', 'GA', 'MD', 'NC', 'NH', 'NJ', 'NY', 'VA', 'PA', 'RI', 'SC', 'DE', 'MA', 'VT']\n",
    "state_name_list = [\n",
    "            'Rhode Island', 'Connecticut', 'Georgia', 'Maryland', 'North Carolina', \n",
    "            'New Hampshire', 'New Jersey', 'New York', 'Virginia',\n",
    "            'Pennsylvania', 'Rhode Island', 'South Carolina', 'Delaware', \n",
    "            'Massachusetts', 'Vermont'\n",
    "            ]\n",
    "state_list_dict = dict(zip(state_list, state_name_list))\n",
    "\n",
    "ASD_no_NA.loc[ASD_no_NA.apply(lambda row: row.state not in state_list, axis=1), 'FLAG'] = 2\n",
    "CD_no_NA.loc[CD_no_NA.apply(lambda row: row.state not in state_list, axis=1), 'FLAG'] = 2\n",
    "\n",
    "# update to the original df\n",
    "ASD_all.update(ASD_no_NA)\n",
    "CD_all.update(CD_no_NA)\n",
    "\n",
    "\n",
    "ASD_all[ASD_all['FLAG']==2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: flag by 3 the records\n",
    "- with town name 'State of XX' or 'State XX' or 'XX State' where XX is the state where the town is located, and \n",
    "- with town name exactly or almost the same as the state name (due to typos).\n",
    "\n",
    "These are records for which \"township\" is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>orig_town</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>60.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>248.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State of New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State of New York</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>738.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>State of New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State of New York</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>State of Vermont</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State of Vermont</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \\\n",
       "2        154.0      20.0           77.0          10.0      192.0       NaN   \n",
       "35        60.0      37.0           30.0          18.0       63.0      83.0   \n",
       "102      248.0      46.0          124.0          23.0      144.0       NaN   \n",
       "122      738.0      43.0          369.0          22.0      708.0      13.0   \n",
       "167       30.0      48.0           15.0          24.0        8.0      22.0   \n",
       "\n",
       "                  town state occupation          orig_town  FLAG  \n",
       "2         Rhode Island    RI     Farmer       Rhode Island   3.0  \n",
       "35        Rhode Island    RI        NaN       Rhode Island   3.0  \n",
       "102  State of New York    NY        NaN  State of New York   3.0  \n",
       "122  State of New York    NY        NaN  State of New York   3.0  \n",
       "167   State of Vermont    VT        NaN   State of Vermont   3.0  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASD_rest = ASD_all[ASD_all['FLAG']==0]\n",
    "CD_rest = CD_all[CD_all['FLAG']==0]\n",
    "\n",
    "# state of XX/state XX - checked\n",
    "ASD_rest.loc[\n",
    "    ASD_rest.apply(lambda row: row.town.lower().startswith('state '), axis=1), 'FLAG'] = 3\n",
    "CD_rest.loc[\n",
    "    CD_rest.apply(lambda row: row.town.lower().startswith('state '), axis=1), 'FLAG'] = 3\n",
    "ASD_rest.loc[ASD_rest.town=='Delaware State', 'FLAG'] = 3\n",
    "CD_rest.loc[CD_rest.town=='Delaware State', 'FLAG'] = 3\n",
    "\n",
    "# town name == state name - checked\n",
    "ASD_rest.loc[ASD_rest.apply(lambda row: row.town==state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "CD_rest.loc[CD_rest.apply(lambda row: row.town==state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "\n",
    "# town name ~= state name - checked\n",
    "ASD_rest.loc[\n",
    "    ASD_rest.apply(lambda row: \n",
    "    process.cdist([row.town], [state_list_dict[row.state]])[0][0] >= 80, axis=1), 'FLAG'\n",
    "    ] = 3\n",
    "CD_rest.loc[\n",
    "    CD_rest.apply(lambda row: \n",
    "    process.cdist([row.town], [state_list_dict[row.state]])[0][0] >= 80, axis=1), 'FLAG'\n",
    "    ] = 3\n",
    "\n",
    "# Carolina in South Carolina (no county named Carolina)\n",
    "ASD_rest.loc[\n",
    "    ASD_rest.apply(lambda row: row.town in state_list_dict[row.state] and\n",
    "    row.town != state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "CD_rest.loc[\n",
    "    CD_rest.apply(lambda row: row.town in state_list_dict[row.state] and\n",
    "    row.town != state_list_dict[row.state], axis=1), 'FLAG'] = 3\n",
    "\n",
    "# update\n",
    "ASD_all.update(ASD_rest)\n",
    "CD_all.update(CD_rest)\n",
    "ASD_all[ASD_all['FLAG']==3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: unify town names\n",
    "- remove `\"state of\" + state_name` and `\"of\" + state_name` that appear in the town name, except \"City of New York\",\n",
    "- remove `\"state\" + state_name` that appears in the town name,\n",
    "- remove `state_name` from `XX + state_name` or `state_name + XX`,\n",
    "- take into account the three special cases.\n",
    "\n",
    "Then, \n",
    "- create a new identifier and remove \"Town\"/\"County\" from town names.\n",
    "\n",
    "Flag this change by 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_rest = ASD_all[ASD_all.FLAG==0]\n",
    "CD_rest = CD_all[CD_all.FLAG==0]\n",
    "\n",
    "def remove_state_from_town(row):\n",
    "    state_name = state_list_dict[row.state]\n",
    "    # state of/of\n",
    "    row.town = row.town.replace(' State of ' + state_name, '')\n",
    "    # state + state_name\n",
    "    row.town = row.town.replace(' State ' + state_name, '')\n",
    "    # special cases\n",
    "    if row.town == 'Boston state Massachusetts':\n",
    "        row.town = 'Boston'\n",
    "\n",
    "    if row.town == 'New Castle County Delaware State':\n",
    "        row.town = 'New Castle County'\n",
    "\n",
    "    if row.town == 'Virginia and Philadelphia':\n",
    "        row.town = 'Philadelphia'\n",
    "\n",
    "    if row.town != 'City of New York':\n",
    "        row.town = row.town.replace(' of ' + state_name, '')\n",
    "        row.town = row.town.replace(state_name, '')\n",
    "    \n",
    "    # flag changes\n",
    "    row.FLAG = 4\n",
    "    return row\n",
    "\n",
    "ASD_rest = ASD_rest.apply(lambda row: remove_state_from_town(row), axis=1)\n",
    "CD_rest = CD_rest.apply(lambda row: remove_state_from_town(row), axis=1)\n",
    "\n",
    "# town_level = 'T' if specified 'Town', 'C' if specified 'County', otherwise 'U'\n",
    "ASD_rest['town_level'] = 'U'\n",
    "ASD_rest.loc[ASD_rest['town'].str.contains('County', na=False), 'town_level'] = 'C'\n",
    "ASD_rest.loc[ASD_rest['town'].str.contains('Town', na=False), 'town_level'] = 'T'\n",
    "\n",
    "def remove_CountyTown(row):\n",
    "    row.town = row.town.replace('County', '')\n",
    "    row.town = row.town.replace('Town', '')\n",
    "    row.FLAG = 4\n",
    "    return row\n",
    "    \n",
    "ASD_rest = ASD_rest.apply(lambda row: remove_CountyTown(row), axis=1)\n",
    "CD_rest = CD_rest.apply(lambda row: remove_CountyTown(row), axis=1)\n",
    "\n",
    "\n",
    "ASD_all.update(ASD_rest)\n",
    "CD_all.update(CD_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: match town names that are likely to be the same one  \n",
    "1. for each state, create a list `A` of town names with # of occurences >= 4; create a list `B` for all the rest towns.\n",
    "2. for each town in list `B`, find the best three matches with towns in list `A` - if above a threshold, report all three and match to the best one. - to be checked afterwards\n",
    "3. all unmatched towns in list `B` become a new list `C` - we WANT to compare one another and if the similarity is above a threshold, group them; otherwise keep it untouched. One simple procedure is for each town in list `C`, group it with all other towns whose distance to it is smaller than a threshold. Then proceed to the next one if it's not in some group already and skip otherwise. This is legitimate because we expect \"typos\" to cause small differences among all mistyped names. Report all the matched and unmatched cases in this round.\n",
    "4. For all above, allow user's input to manually confirm the matches.\n",
    "\n",
    "Flag this change by 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_towns(df):\n",
    "    if len(df.index)==0:    # Vermont\n",
    "        return df\n",
    "    print(f\"State: {df.state.iloc[0]}\")\n",
    "\n",
    "    val_counts = df.town.value_counts(sort=True)\n",
    "    list_A, list_B = list(val_counts[val_counts>=min(val_counts.iloc[0], 4)].index), list(val_counts[val_counts<min(val_counts.iloc[0], 6)].index)\n",
    "    list_C = list_B.copy()\n",
    "    for town in list_B:\n",
    "        best3 = process.extract(town, list_A)[0:3]\n",
    "        if best3[0][1] >= 85:\n",
    "            print(f\"{town}. Candidates: {[x[0] for x in best3]}. Matched: {best3[0][0]}.\\n\")\n",
    "\n",
    "            # # user input\n",
    "            # ACCEPT = input(\"1 for ACCEPT. 0 for REJECT\")\n",
    "            # # records\n",
    "\n",
    "            # if ACCEPT==1:\n",
    "            # matched to list_A\n",
    "            list_C.remove(town)\n",
    "            df.loc[df.town==town, 'FLAG'] = 5\n",
    "            df.loc[df.town==town, 'town'] = best3[0][0]\n",
    "\n",
    "    list_C_flag = [-1 for x in list_C]\n",
    "    for id, town in enumerate(list_C):\n",
    "        # only do matching if not already matched\n",
    "        if list_C_flag[id] == -1:\n",
    "            bests = [x[0] for x in process.extract(town, list_C, score_cutoff=85)]\n",
    "            if len(bests) > 1:\n",
    "                # if not just oneself\n",
    "                indexes = [list_C.index(x) for x in bests]\n",
    "                # make sure same group has the same id\n",
    "                print(f\"Candidate group: {bests}\")\n",
    "\n",
    "                # pick the shortest one as the name we want to keep\n",
    "                # this deals with the cases like North Hampton -> Hampton\n",
    "                index_selected = list_C.index(min(bests, key=len))\n",
    "                \n",
    "                for k in indexes: \n",
    "                    list_C_flag[k] = index_selected \n",
    "\n",
    "                # one special case\n",
    "                if bests==['Cumberland', 'Cumb  ']:\n",
    "                    list_C_flag[k] = list_C.index('Cumberland')\n",
    "    \n",
    "    for id, flag in enumerate(list_C_flag):\n",
    "        if flag != -1:\n",
    "            df.loc[df.town==list_C[id], 'FLAG'] = 5\n",
    "            df.loc[df.town==list_C[id], 'town'] = list_C[flag]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: RI\n",
      "Johnson. Candidates: ['Johnson', 'Johnston', 'South Kingston']. Matched: Johnson.\n",
      "\n",
      "Portsmouth. Candidates: ['Portsmouth', 'North Providence', 'South Kingston']. Matched: Portsmouth.\n",
      "\n",
      "Richmond. Candidates: ['Richmond', 'East Greenwich', 'West Greenwich']. Matched: Richmond.\n",
      "\n",
      "Conventry. Candidates: ['Coventry', 'Exeter', 'North Providence']. Matched: Coventry.\n",
      "\n",
      "Glocester. Candidates: ['Gloucester', 'Exeter', 'Coventry']. Matched: Gloucester.\n",
      "\n",
      "North Kingstone. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "North Kingstown. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Stoughton now of Providence. Candidates: ['Providence', 'North Providence', 'Johnston']. Matched: Providence.\n",
      "\n",
      "Smithfeild. Candidates: ['Smithfield', 'Scituate', 'Cumberland']. Matched: Smithfield.\n",
      "\n",
      "South Kingstone. Candidates: ['South Kingston', 'North Kingston', 'Johnston']. Matched: South Kingston.\n",
      "\n",
      "Warnick. Candidates: ['Warwick', 'Warren', 'East Greenwich']. Matched: Warwick.\n",
      "\n",
      "State: RI\n",
      "Coventry. Candidates: ['Coventry', 'North Providence', 'Providence']. Matched: Coventry.\n",
      "\n",
      "North Kingston. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Johnston. Candidates: ['Johnston', 'Johnson', 'South Kingston']. Matched: Johnston.\n",
      "\n",
      "Johnson. Candidates: ['Johnson', 'Johnston', 'South Kingston']. Matched: Johnson.\n",
      "\n",
      "North Kingstown. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Stoughton now of Providence. Candidates: ['Providence', 'North Providence', 'Johnston']. Matched: Providence.\n",
      "\n",
      "South Kingstone. Candidates: ['South Kingston', 'North Kingston', 'Johnston']. Matched: South Kingston.\n",
      "\n",
      "North Kingstone. Candidates: ['North Kingston', 'South Kingston', 'Newport']. Matched: North Kingston.\n",
      "\n",
      "Smithfeild. Candidates: ['Smithfield', 'Scituate', 'North Providence']. Matched: Smithfield.\n",
      "\n",
      "State: CT\n",
      "Huntington. Candidates: ['Huntington', 'Groton', 'Stonington']. Matched: Huntington.\n",
      "\n",
      "Montville. Candidates: ['Montville', 'Lyme', 'Mansfield']. Matched: Montville.\n",
      "\n",
      "Plainfield. Candidates: ['Plainfield', 'Fairfield', 'Mansfield']. Matched: Plainfield.\n",
      "\n",
      "Tolland. Candidates: ['Tolland', 'Plainfield', 'Bolton']. Matched: Tolland.\n",
      "\n",
      "Canterbury. Candidates: ['Canterbury', 'Danbury', 'Glastonbury']. Matched: Canterbury.\n",
      "\n",
      "Berlin. Candidates: ['Berlin', 'Bolton', 'Hebron']. Matched: Berlin.\n",
      "\n",
      "Thompson. Candidates: ['Thompson', 'Preston', 'Stonington']. Matched: Thompson.\n",
      "\n",
      "Torrington. Candidates: ['Torrington', 'Stonington', 'Groton']. Matched: Torrington.\n",
      "\n",
      "Haddam. Candidates: ['East Haddam', 'Chatham', 'Windham']. Matched: East Haddam.\n",
      "\n",
      "Stonnington. Candidates: ['Stonington', 'Torrington', 'Groton']. Matched: Stonington.\n",
      "\n",
      "Stafford. Candidates: ['Stamford', 'Stratford', 'East Hartford']. Matched: Stamford.\n",
      "\n",
      "New Hartford. Candidates: ['Hartford', 'East Hartford', 'New Milford']. Matched: Hartford.\n",
      "\n",
      "Middletown . Candidates: ['Middletown', 'Bolton', 'Groton']. Matched: Middletown.\n",
      "\n",
      "Colchestert. Candidates: ['Colchester', 'Coventry', 'Norwich']. Matched: Colchester.\n",
      "\n",
      "London. Candidates: ['New London', 'Lebanon', 'Bolton']. Matched: New London.\n",
      "\n",
      "Wethersfield in t. Candidates: ['Wethersfield', 'Suffield', 'Mansfield']. Matched: Wethersfield.\n",
      "\n",
      "Candidate group: ['Cornwall', 'Cornwell']\n",
      "Candidate group: ['Brooklyn', 'Brooklyne']\n",
      "Candidate group: ['Volentown', 'Voluntown']\n",
      "Candidate group: ['Southhampton', 'Hampton']\n",
      "Candidate group: ['Northampton', 'Hampton']\n",
      "State: CT\n",
      "Montville. Candidates: ['Montville', 'Lyme', 'Mansfield']. Matched: Montville.\n",
      "\n",
      "Huntington. Candidates: ['Huntington', 'Groton', 'Stonington']. Matched: Huntington.\n",
      "\n",
      "Torrington. Candidates: ['Torrington', 'Stonington', 'Groton']. Matched: Torrington.\n",
      "\n",
      "Tolland. Candidates: ['Tolland', 'Plainfield', 'Bolton']. Matched: Tolland.\n",
      "\n",
      "Ashford. Candidates: ['Ashford', 'East Hartford', 'Hartford']. Matched: Ashford.\n",
      "\n",
      "Thompson. Candidates: ['Thompson', 'Preston', 'Stonington']. Matched: Thompson.\n",
      "\n",
      "Canterbury. Candidates: ['Canterbury', 'Danbury', 'Glastonbury']. Matched: Canterbury.\n",
      "\n",
      "Berlin. Candidates: ['Berlin', 'Bolton', 'Hebron']. Matched: Berlin.\n",
      "\n",
      "Plainfield. Candidates: ['Plainfield', 'Fairfield', 'Mansfield']. Matched: Plainfield.\n",
      "\n",
      "Stonnington. Candidates: ['Stonington', 'Torrington', 'Groton']. Matched: Stonington.\n",
      "\n",
      "Haddam. Candidates: ['East Haddam', 'Chatham', 'Windham']. Matched: East Haddam.\n",
      "\n",
      "Stafford. Candidates: ['Stamford', 'Stratford', 'East Hartford']. Matched: Stamford.\n",
      "\n",
      "New Hartford. Candidates: ['Hartford', 'East Hartford', 'New Milford']. Matched: Hartford.\n",
      "\n",
      "London. Candidates: ['New London', 'Lebanon', 'Bolton']. Matched: New London.\n",
      "\n",
      "Candidate group: ['Cornwall', 'Cornwell']\n",
      "Candidate group: ['Brooklyn', 'Brooklyne']\n",
      "Candidate group: ['Volentown', 'Voluntown']\n",
      "Candidate group: ['Hampton', 'Southhampton', 'Northampton']\n",
      "State: GA\n",
      "State: GA\n",
      "State: MD\n",
      "Somerset . Candidates: ['Somerset ', 'St Marys ', 'Montgomery ']. Matched: Somerset .\n",
      "\n",
      "Cambridge. Candidates: ['Cambridge', 'Charles ', 'George ']. Matched: Cambridge.\n",
      "\n",
      "Washington . Candidates: ['Washington ', 'George ', 'Prince Georges ']. Matched: Washington .\n",
      "\n",
      "Queen Annes . Candidates: ['Queen Annes ', 'Anne Arundel ', 'Charles ']. Matched: Queen Annes .\n",
      "\n",
      "Montgomery  . Candidates: ['Montgomery ', 'George ', 'St Marys ']. Matched: Montgomery .\n",
      "\n",
      "Frederick  . Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "George town. Candidates: ['George ', 'Prince Georges ', 'Somerset ']. Matched: George .\n",
      "\n",
      "Frederick. Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "Georges . Candidates: ['George ', 'Prince Georges ', 'Dorchester ']. Matched: George .\n",
      "\n",
      "Somerset  . Candidates: ['Somerset ', 'St Marys ', 'Montgomery ']. Matched: Somerset .\n",
      "\n",
      "Candidate group: ['Talbot ', 'Talbot']\n",
      "Candidate group: ['Calvert ', 'Calver ']\n",
      "State: MD\n",
      "Somerset . Candidates: ['Somerset ', 'St Marys ', 'Montgomery ']. Matched: Somerset .\n",
      "\n",
      "Cambridge. Candidates: ['Cambridge', 'Charles ', 'George ']. Matched: Cambridge.\n",
      "\n",
      "Washington . Candidates: ['Washington ', 'George ', 'Prince Georges ']. Matched: Washington .\n",
      "\n",
      "Queen Annes . Candidates: ['Queen Annes ', 'Anne Arundel ', 'Charles ']. Matched: Queen Annes .\n",
      "\n",
      "Montgomery  . Candidates: ['Montgomery ', 'George ', 'St Marys ']. Matched: Montgomery .\n",
      "\n",
      "Frederick  . Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "George town. Candidates: ['George ', 'Prince Georges ', 'Somerset ']. Matched: George .\n",
      "\n",
      "Frederick. Candidates: ['Frederick ', 'Dorchester ', 'George ']. Matched: Frederick .\n",
      "\n",
      "Georges . Candidates: ['George ', 'Prince Georges ', 'Dorchester ']. Matched: George .\n",
      "\n",
      "Somerset  . Candidates: ['Somerset ', 'St Marys ', 'Montgomery ']. Matched: Somerset .\n",
      "\n",
      "Candidate group: ['Talbot ', 'Talbot']\n",
      "Candidate group: ['Calvert ', 'Calver ']\n",
      "State: NC\n",
      "Rowan . Candidates: ['Rowan ', 'Edenton', 'Newbern']. Matched: Rowan .\n",
      "\n",
      "State: NC\n",
      "Rowan . Candidates: ['Rowan ', 'Edenton', 'Newbern']. Matched: Rowan .\n",
      "\n",
      "State: NH\n",
      "Canterbury. Candidates: ['Canterbury', 'Exeter', 'Concord']. Matched: Canterbury.\n",
      "\n",
      "Kensington. Candidates: ['Kensington', 'Exeter', 'Concord']. Matched: Kensington.\n",
      "\n",
      "Portsmouth . Candidates: ['Portsmouth', 'Concord', 'Exeter']. Matched: Portsmouth.\n",
      "\n",
      "Candidate group: ['South Hampton', 'Hampton']\n",
      "Candidate group: ['Londonberry', 'London']\n",
      "Candidate group: ['Charleston', 'Charlestown']\n",
      "Candidate group: ['North Hampton', 'Hampton']\n",
      "Candidate group: ['Newport in ', 'Newport ']\n",
      "State: NH\n",
      "Kensington. Candidates: ['Kensington', 'Exeter', 'Concord']. Matched: Kensington.\n",
      "\n",
      "Canterbury. Candidates: ['Canterbury', 'Exeter', 'Concord']. Matched: Canterbury.\n",
      "\n",
      "Portsmouth . Candidates: ['Portsmouth', 'Concord', 'Exeter']. Matched: Portsmouth.\n",
      "\n",
      "Candidate group: ['South Hampton', 'Hampton']\n",
      "Candidate group: ['Charleston', 'Charlestown']\n",
      "Candidate group: ['Londonberry', 'London']\n",
      "Candidate group: ['North Hampton', 'Hampton']\n",
      "State: NJ\n",
      "Candidate group: ['Brunswick ', 'New Brunswick ']\n",
      "Candidate group: ['Cape May ', 'Cape May']\n",
      "State: NJ\n",
      "Candidate group: ['Brunswick ', 'New Brunswick ']\n",
      "Candidate group: ['Cape May ', 'Cape May']\n",
      "State: NY\n",
      "State: NY\n",
      "State: VA\n",
      "Candidate group: ['Alexandria', 'Alexandria ']\n",
      "State: VA\n",
      "Candidate group: ['Alexandria', 'Alexandria ']\n",
      "State: PA\n",
      "Northern Liberties. Candidates: ['Northern Liberties', 'Berks  ', 'Berks ']. Matched: Northern Liberties.\n",
      "\n",
      "Berks . Candidates: ['Berks  ', 'Berks ', 'Reading Berks ']. Matched: Berks  .\n",
      "\n",
      "Bethlehem. Candidates: ['Bethlehem', 'Berks  ', 'Berks ']. Matched: Bethlehem.\n",
      "\n",
      "Reading. Candidates: ['Reading', 'Reading ', 'Reading Berks ']. Matched: Reading.\n",
      "\n",
      "Franklin  . Candidates: ['Franklin  ', 'Reading', 'Reading ']. Matched: Franklin  .\n",
      "\n",
      "Germantown. Candidates: ['Germantown', 'Berks  ', 'Berks ']. Matched: Germantown.\n",
      "\n",
      "Reading . Candidates: ['Reading', 'Reading ', 'Reading Berks ']. Matched: Reading.\n",
      "\n",
      "Chester  Pennsylvaina. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Franklin . Candidates: ['Franklin  ', 'Reading', 'Reading ']. Matched: Franklin  .\n",
      "\n",
      "Philadephia. Candidates: ['Philadelphia', 'Philadelphia ', 'Bethlehem']. Matched: Philadelphia.\n",
      "\n",
      " Berks . Candidates: ['Berks  ', 'Berks ', 'Reading Berks ']. Matched: Berks  .\n",
      "\n",
      "Chester Co . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Hatter Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      " of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Bethlehem']. Matched: Philadelphia.\n",
      "\n",
      "Montgomery  . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Northumberland  . Candidates: ['Northumberland ', 'Berks  ', 'Berks ']. Matched: Northumberland .\n",
      "\n",
      "Church on Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      "Philadelphila. Candidates: ['Philadelphia', 'Philadelphia ', 'Carlisle ']. Matched: Philadelphia.\n",
      "\n",
      "Northumberland  Virginia. Candidates: ['Northumberland ', 'Northern Liberties', 'Berks  ']. Matched: Northumberland .\n",
      "\n",
      "German . Candidates: ['Germantown', 'Northumberland ', 'Northern Liberties']. Matched: Germantown.\n",
      "\n",
      "Northan Liberties. Candidates: ['Northern Liberties', 'Franklin  ', 'Berks  ']. Matched: Northern Liberties.\n",
      "\n",
      " Montgomery . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "The N Lib of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Northern Liberties']. Matched: Philadelphia.\n",
      "\n",
      "Montgomery. Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Frankford Philadelphia . Candidates: ['Philadelphia', 'Philadelphia ', 'Franklin  ']. Matched: Philadelphia.\n",
      "\n",
      "Chester. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Chester and . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Northum  . Candidates: ['Northumberland ', 'Northern Liberties', 'York  ']. Matched: Northumberland .\n",
      "\n",
      "Candidate group: ['Westmoreland ', 'Westmoreland  ', 'Westmoreland']\n",
      "Candidate group: ['Dauphin ', 'Dauphin  ', 'Dauphin and Company', 'Paxton Tot Dauphin ']\n",
      "Candidate group: ['Northampton  ', 'Northampton ']\n",
      "Candidate group: ['Pittsburgh ', 'Pittsburgh']\n",
      "Candidate group: ['Delaware', 'Delaware ', 'Delaware  ']\n",
      "Candidate group: ['Allegheny  ', 'Allegheny ']\n",
      "Candidate group: ['Kensington', 'Kensignton']\n",
      "Candidate group: ['Cumberland', 'Cumb  ']\n",
      "State: PA\n",
      "Berks . Candidates: ['Berks  ', 'Berks ', 'Reading Berks ']. Matched: Berks  .\n",
      "\n",
      "Bethlehem. Candidates: ['Bethlehem', 'Berks  ', 'Berks ']. Matched: Bethlehem.\n",
      "\n",
      "Northern Liberties. Candidates: ['Northern Liberties', 'Berks  ', 'Berks ']. Matched: Northern Liberties.\n",
      "\n",
      "Germantown. Candidates: ['Germantown', 'Berks  ', 'Berks ']. Matched: Germantown.\n",
      "\n",
      "Franklin  . Candidates: ['Franklin  ', 'Reading', 'Reading ']. Matched: Franklin  .\n",
      "\n",
      "Reading. Candidates: ['Reading', 'Reading ', 'Reading Berks ']. Matched: Reading.\n",
      "\n",
      "Reading . Candidates: ['Reading', 'Reading ', 'Reading Berks ']. Matched: Reading.\n",
      "\n",
      "Chester  Pennsylvaina. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Franklin . Candidates: ['Franklin  ', 'Reading', 'Reading ']. Matched: Franklin  .\n",
      "\n",
      " Berks . Candidates: ['Berks  ', 'Berks ', 'Reading Berks ']. Matched: Berks  .\n",
      "\n",
      "Chester Co . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Montgomery  . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Hatter Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      "German . Candidates: ['Germantown', 'Northumberland ', 'Northern Liberties']. Matched: Germantown.\n",
      "\n",
      "Philadelphila. Candidates: ['Philadelphia', 'Philadelphia ', 'Carlisle ']. Matched: Philadelphia.\n",
      "\n",
      "Northumberland  Virginia. Candidates: ['Northumberland ', 'Northern Liberties', 'Berks  ']. Matched: Northumberland .\n",
      "\n",
      "Church on Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Chester  ']. Matched: Philadelphia.\n",
      "\n",
      "Northumberland  . Candidates: ['Northumberland ', 'Berks  ', 'Berks ']. Matched: Northumberland .\n",
      "\n",
      "Chester and . Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      "Northum  . Candidates: ['Northumberland ', 'Northern Liberties', 'York  ']. Matched: Northumberland .\n",
      "\n",
      "Chester. Candidates: ['Chester  ', 'Chester ', 'Lancaster']. Matched: Chester  .\n",
      "\n",
      " of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Bethlehem']. Matched: Philadelphia.\n",
      "\n",
      "Northan Liberties. Candidates: ['Northern Liberties', 'Franklin  ', 'Berks  ']. Matched: Northern Liberties.\n",
      "\n",
      "Montgomery. Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "The N Lib of Philadelphia. Candidates: ['Philadelphia', 'Philadelphia ', 'Northern Liberties']. Matched: Philadelphia.\n",
      "\n",
      " Montgomery . Candidates: ['Montgomery ', 'York  ', 'York ']. Matched: Montgomery .\n",
      "\n",
      "Frankford Philadelphia . Candidates: ['Philadelphia', 'Philadelphia ', 'Franklin  ']. Matched: Philadelphia.\n",
      "\n",
      "Candidate group: ['Northampton  ', 'Northampton ']\n",
      "Candidate group: ['Dauphin ', 'Dauphin  ', 'Dauphin and Company', 'Paxton Tot Dauphin ']\n",
      "Candidate group: ['Westmoreland ', 'Westmoreland  ', 'Westmoreland']\n",
      "Candidate group: ['Pittsburgh ', 'Pittsburgh']\n",
      "Candidate group: ['Allegheny  ', 'Allegheny ']\n",
      "Candidate group: ['Delaware', 'Delaware ', 'Delaware  ']\n",
      "Candidate group: ['Kensington', 'Kensignton']\n",
      "Candidate group: ['Cumberland', 'Cumb  ']\n",
      "State: RI\n",
      "Johnson. Candidates: ['Johnson', 'Johnston', 'North Kingston']. Matched: Johnson.\n",
      "\n",
      "Portsmouth. Candidates: ['Portsmouth', 'North Providence', 'South Kingston']. Matched: Portsmouth.\n",
      "\n",
      "Richmond. Candidates: ['Richmond', 'East Greenwich', 'West Greenwich']. Matched: Richmond.\n",
      "\n",
      "State: RI\n",
      "Coventry. Candidates: ['Coventry', 'North Providence', 'Providence']. Matched: Coventry.\n",
      "\n",
      "Johnston. Candidates: ['Johnston', 'Johnson', 'South Kingston']. Matched: Johnston.\n",
      "\n",
      "Johnson. Candidates: ['Johnson', 'Johnston', 'South Kingston']. Matched: Johnson.\n",
      "\n",
      "State: SC\n",
      "Charleston . Candidates: ['Charleston', 'Charleston ', 'Santee']. Matched: Charleston.\n",
      "\n",
      "St Eustatius. Candidates: ['St Eustatius', 'Santee', 'Charleston']. Matched: St Eustatius.\n",
      "\n",
      "Santee. Candidates: ['Santee', 'St Eustatius', 'Charleston']. Matched: Santee.\n",
      "\n",
      "Charleston  . Candidates: ['Charleston', 'Charleston ', 'Santee']. Matched: Charleston.\n",
      "\n",
      "St James Santee. Candidates: ['Santee', 'St Eustatius', 'Charleston']. Matched: Santee.\n",
      "\n",
      "St Lukes. Candidates: ['St Eustatius', 'Santee', 'Charleston']. Matched: St Eustatius.\n",
      "\n",
      "St James Parish Santee. Candidates: ['Santee', 'St Eustatius', 'Charleston']. Matched: Santee.\n",
      "\n",
      "St George's Parish. Candidates: ['St Eustatius', 'Santee', 'Charleston']. Matched: St Eustatius.\n",
      "\n",
      "Candidate group: ['Camden', 'Camden District']\n",
      "Candidate group: [\"St Bartholomew's\", \"St Luke's\", 'St Helena', \"Bartholomew's Parish\"]\n",
      "Candidate group: [\"St John's Parish\", \"St Johnn's Parish\", \"St Luke's\", 'St Helena']\n",
      "Candidate group: ['St Gustavus', \"St Johnn's Parish\"]\n",
      "Candidate group: [\"John's Island\", \"Bartholomew's Parish\"]\n",
      "State: SC\n",
      "Charleston . Candidates: ['Charleston', 'Charleston ', 'Georgetown']. Matched: Charleston.\n",
      "\n",
      "James Island. Candidates: ['James Island', 'Camden', 'Charleston']. Matched: James Island.\n",
      "\n",
      "Camden. Candidates: ['Camden', 'James Island', 'Charleston']. Matched: Camden.\n",
      "\n",
      "Charleston  . Candidates: ['Charleston', 'Charleston ', 'Georgetown']. Matched: Charleston.\n",
      "\n",
      "Charlestom. Candidates: ['Charleston', 'Charleston ', 'Camden']. Matched: Charleston.\n",
      "\n",
      "Camden Planter. Candidates: ['Camden', 'James Island', 'Charleston']. Matched: Camden.\n",
      "\n",
      "Candidate group: ['Ninety six District', '96 District']\n",
      "Candidate group: ['St Pauls', \"St. Paul's\"]\n",
      "Candidate group: ['Richard ', 'Richard Sennings']\n",
      "State: DE\n",
      " Newcastle . Candidates: ['New Castle ']. Matched: New Castle .\n",
      "\n",
      "State: DE\n",
      " Newcastle . Candidates: ['New Castle ']. Matched: New Castle .\n",
      "\n",
      "State: MA\n",
      "Andover. Candidates: ['Andover', 'Haverhill', 'Swansea']. Matched: Andover.\n",
      "\n",
      "Swansea. Candidates: ['Swansea', 'Andover', 'Newbury Port']. Matched: Swansea.\n",
      "\n",
      "Haverhill. Candidates: ['Haverhill', 'Andover', 'Beverly']. Matched: Haverhill.\n",
      "\n",
      "Dighton. Candidates: ['Dighton', 'Boston', 'Attleborough']. Matched: Dighton.\n",
      "\n",
      "Cambridge. Candidates: ['Cambridge', 'Springfield', 'Attleborough']. Matched: Cambridge.\n",
      "\n",
      "Beverly. Candidates: ['Beverly', 'Haverhill', 'Andover']. Matched: Beverly.\n",
      "\n",
      "Springfield. Candidates: ['Springfield', 'Cambridge', 'Beverly']. Matched: Springfield.\n",
      "\n",
      "Cambridge . Candidates: ['Cambridge', 'Springfield', 'Attleborough']. Matched: Cambridge.\n",
      "\n",
      "Candidate group: ['Grafton', 'Grafton ']\n",
      "Candidate group: ['Tyringham MA', 'Tyringham ']\n",
      "State: MA\n",
      "Swansea. Candidates: ['Swansea', 'Andover', 'Newbury Port']. Matched: Swansea.\n",
      "\n",
      "Andover. Candidates: ['Andover', 'Haverhill', 'Swansea']. Matched: Andover.\n",
      "\n",
      "Haverhill. Candidates: ['Haverhill', 'Andover', 'Beverly']. Matched: Haverhill.\n",
      "\n",
      "Dighton. Candidates: ['Dighton', 'Boston', 'Attleborough']. Matched: Dighton.\n",
      "\n",
      "Springfield. Candidates: ['Springfield', 'Beverly', 'Swansea']. Matched: Springfield.\n",
      "\n",
      "Beverly. Candidates: ['Beverly', 'Haverhill', 'Andover']. Matched: Beverly.\n",
      "\n",
      "Candidate group: ['Cambridge', 'Cambridge ']\n",
      "Candidate group: ['Tyringham MA', 'Tyringham ']\n"
     ]
    }
   ],
   "source": [
    "for state_code in state_list:\n",
    "    \n",
    "    ASD_rest[ASD_rest.state==state_code] = match_towns(ASD_rest[ASD_rest.state==state_code])\n",
    "    CD_rest[CD_rest.state==state_code] = match_towns(CD_rest[CD_rest.state==state_code])\n",
    "\n",
    "\n",
    "# deal with some other special cases\n",
    "ASD_rest.loc[ASD_rest.town=='East Haddam', 'town'] = 'Haddam'\n",
    "CD_rest.loc[CD_rest.town=='East Haddam', 'town'] = 'Haddam'\n",
    "\n",
    "ASD_all.update(ASD_rest)\n",
    "CD_all.update(CD_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now maps to the County-town list\n",
    "\n",
    "There are a few cases where the `orig_town` names include `'County'`, but gets mapped to nothing on the list. We assign `county` to `name_type` in this case, and let `county` be county name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_town</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>name_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Hartford County</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolton</td>\n",
       "      <td>CT</td>\n",
       "      <td>Tolland County</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wethersfield</td>\n",
       "      <td>CT</td>\n",
       "      <td>Hartford County</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lyme</td>\n",
       "      <td>CT</td>\n",
       "      <td>New London County</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_town state             county name_type\n",
       "0      Hartford    CT    Hartford County      town\n",
       "1        Bolton    CT     Tolland County      town\n",
       "2  Rhode Island    RI                NaN     state\n",
       "5  Wethersfield    CT    Hartford County      town\n",
       "6          Lyme    CT  New London County      town"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASD_no_NA = ASD_all[ASD_all['FLAG']!=1]\n",
    "CD_no_NA = CD_all[CD_all['FLAG']!=1]\n",
    "\n",
    "matchlist = pd.read_csv('countymapping.csv', index_col=0)\n",
    "matchlist = matchlist.rename({'town': 'orig_town'}, axis=1)\n",
    "matchlist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>orig_town</th>\n",
       "      <th>FLAG</th>\n",
       "      <th>county</th>\n",
       "      <th>name_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>80.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>Berks</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pennsylvania Berks County</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>511.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>255.0</td>\n",
       "      <td>81.00</td>\n",
       "      <td>230.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>Berks</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pennsylvania Berks County</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>233.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pennsylvania Montgomery County</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>253.0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>290.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>Northumberland</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northumberland County Virginia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>1634.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Pendleton</td>\n",
       "      <td>SC</td>\n",
       "      <td>Planter</td>\n",
       "      <td>Pendleton County</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \\\n",
       "2155       80.0     28.00           40.0         15.00       28.0     90.00   \n",
       "2156      511.0     63.00          255.0         81.00      230.0     13.00   \n",
       "2157      233.0     10.00          116.0         55.00      112.0      8.00   \n",
       "2680      253.0     49.00          126.0         74.00      290.0     23.00   \n",
       "4037     1634.0     -0.14         1634.0         -0.08     1634.0      0.38   \n",
       "\n",
       "                 town state occupation                       orig_town  FLAG  \\\n",
       "2155          Berks      PA        NaN       Pennsylvania Berks County   5.0   \n",
       "2156          Berks      PA        NaN       Pennsylvania Berks County   5.0   \n",
       "2157      Montgomery     PA        NaN  Pennsylvania Montgomery County   5.0   \n",
       "2680  Northumberland     PA        NaN  Northumberland County Virginia   5.0   \n",
       "4037       Pendleton     SC    Planter                Pendleton County   4.0   \n",
       "\n",
       "     county name_type  \n",
       "2155    NaN       NaN  \n",
       "2156    NaN       NaN  \n",
       "2157    NaN       NaN  \n",
       "2680    NaN       NaN  \n",
       "4037    NaN       NaN  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASD_merged = pd.merge(left=ASD_no_NA, right=matchlist, how='left', on=['state', 'orig_town'])\n",
    "CD_merged = pd.merge(left=ASD_no_NA, right=matchlist, how='left', on=['state', 'orig_town'])\n",
    "\n",
    "\n",
    "# select\n",
    "filter_ASD = ASD_merged.orig_town.str.contains('County') & ASD_merged.name_type.isna()\n",
    "filter_CD = CD_merged.orig_town.str.contains('County') & CD_merged.name_type.isna()\n",
    "ASD_merged.loc[filter_ASD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>orig_town</th>\n",
       "      <th>FLAG</th>\n",
       "      <th>county</th>\n",
       "      <th>name_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>532.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>508.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449.0</td>\n",
       "      <td>96.00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>97.00</td>\n",
       "      <td>232.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>CT</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tolland</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>172.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>CT</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>112.0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>978.0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>978.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>978.0</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1900.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>SC</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>1106.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>SC</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>219.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>219.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>Savannah</td>\n",
       "      <td>GA</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>Savannah</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chatham</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4074 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \\\n",
       "0        1064.0     75.00          532.0         37.00      508.0     51.00   \n",
       "1         449.0     96.00          224.0         97.00      232.0     10.00   \n",
       "2         154.0     20.00           77.0         10.00      192.0       NaN   \n",
       "3         196.0     75.00           98.0         37.00      172.0     24.00   \n",
       "4          53.0     58.00           26.0         79.00       67.0      6.00   \n",
       "...         ...       ...            ...           ...        ...       ...   \n",
       "4069      112.0     -0.40          112.0           NaN      112.0       NaN   \n",
       "4070      978.0     -0.20          978.0         -0.47      978.0     -0.21   \n",
       "4071     1900.0      0.00         1900.0         -0.24     1900.0      0.00   \n",
       "4072     1106.0      0.00         1106.0           NaN     1106.0       NaN   \n",
       "4073      219.0      0.04          219.0         -0.48      219.0      0.28   \n",
       "\n",
       "                town state occupation       orig_town  FLAG      county  \\\n",
       "0           Hartford    CT   Merchant        Hartford   4.0    Hartford   \n",
       "1             Bolton    CT     Farmer          Bolton   4.0     Tolland   \n",
       "2       Rhode Island    RI     Farmer    Rhode Island   3.0         NaN   \n",
       "3           Hartford    CT   Merchant        Hartford   4.0    Hartford   \n",
       "4           Hartford    CT   Merchant        Hartford   4.0    Hartford   \n",
       "...              ...   ...        ...             ...   ...         ...   \n",
       "4069      Charleston    SC        NaN      Charleston   4.0  Charleston   \n",
       "4070  North Carolina    NC        NaN  North Carolina   3.0         NaN   \n",
       "4071      Charleston    SC   Merchant      Charleston   4.0  Charleston   \n",
       "4072      Charleston    SC   Merchant      Charleston   4.0  Charleston   \n",
       "4073        Savannah    GA   Merchant        Savannah   4.0     Chatham   \n",
       "\n",
       "     name_type  \n",
       "0         town  \n",
       "1         town  \n",
       "2        state  \n",
       "3         town  \n",
       "4         town  \n",
       "...        ...  \n",
       "4069      town  \n",
       "4070     state  \n",
       "4071      town  \n",
       "4072      town  \n",
       "4073      town  \n",
       "\n",
       "[4074 rows x 13 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASD_merged.loc[filter, 'name_type'] = 'county'\n",
    "ASD_merged.loc[filter, 'county'] = ASD_merged.loc[filter, 'town']\n",
    "\n",
    "CD_merged.loc[filter, 'name_type'] = 'county'\n",
    "CD_merged.loc[filter, 'county'] = CD_merged.loc[filter, 'town']\n",
    "\n",
    "# remove \"County\" from county name\n",
    "ASD_merged['county'] = ASD_merged['county'].apply(lambda x: x.replace('County', '').rstrip() if type(x)==str else x)\n",
    "CD_merged['county'] = CD_merged['county'].apply(lambda x: x.replace('County', '').rstrip() if type(x)==str else x)\n",
    "\n",
    "ASD_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign nan to town if name_type == county/state\n",
    "ASD_merged.loc[(ASD_merged.name_type=='county') | (ASD_merged.name_type=='state'), 'town'] = np.nan\n",
    "CD_merged.loc[(CD_merged.name_type=='county') | (CD_merged.name_type=='state'), 'town'] = np.nan\n",
    "\n",
    "ASD_df= ASD_merged.drop(['orig_town'], axis=1)\n",
    "CD_df = CD_merged.drop(['orig_town'], axis=1)\n",
    "\n",
    "# remove na cases and others\n",
    "ASD_df = ASD_df.loc[(~ASD_merged.name_type.isna()) & (ASD_merged.name_type!='other')]\n",
    "CD_df = CD_df.loc[(~CD_merged.name_type.isna()) & (CD_merged.name_type!='other')]\n",
    "\n",
    "ASD_df = ASD_df.fillna('NaN')\n",
    "CD_df = CD_df.fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_df.groupby(['state', 'county', 'town'], dropna=False).size().to_csv('ASD_counts.csv')\n",
    "CD_df.groupby(['state', 'county', 'town'], dropna=False).size().to_csv('CD_counts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

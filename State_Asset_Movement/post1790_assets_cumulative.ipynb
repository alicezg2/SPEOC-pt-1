{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "from os.path import exists\n",
    "import itertools\n",
    "from whoswho import who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringConvert(x):\n",
    "    return x.replace(\"  \", \" \") if type(x) == str else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineLists(lst):\n",
    "    returnlst = []\n",
    "    for sublist in lst:\n",
    "        if type(sublist) == list:\n",
    "            returnlst.extend([item for item in sublist])\n",
    "        else:\n",
    "            returnlst.append(sublist)\n",
    "    return returnlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that makes dictionary that combines 3 full name columns into 1\n",
    "def genFullNameList(namelst): \n",
    "    #remove duplicates and nulls\n",
    "    namelst = list(set([name for name in namelst if not pd.isnull(name)]))\n",
    "    namelst = sorted(namelst, key=len)\n",
    "    #remove names that are really similar\n",
    "    namelstnew = namelst\n",
    "    if len(namelst) > 1:\n",
    "        namelstnew = []\n",
    "        name1 = namelst[0]\n",
    "        namelstnew.append(name1)\n",
    "        for name in namelst[1:]:\n",
    "            score1  = process.extract(name1, [name])[0][1]\n",
    "            score2 = who.match(name1, name)\n",
    "            #only add names if they are dissimilar - fuzzy score 70 or less\n",
    "            if score1 <= 70:\n",
    "                namelstnew.append(name)\n",
    "    return namelstnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFuzzyDict(df):\n",
    "    namelst = list(set([name for namelist in df['full name prelim'] for name in namelist]))\n",
    "    #create dictionary that matches similar names together\n",
    "    fn_fuzzy_pre = dict()\n",
    "    for name in namelst:\n",
    "        marker = False\n",
    "        if not pd.isnull(name):\n",
    "            #find matches for name\n",
    "            match = process.extract(name, [x for x in namelst if x != name and not \n",
    "                                           pd.isnull(x)], limit = 1, score_cutoff = 90)\n",
    "            if len(match)> 0:\n",
    "                match = match[0]\n",
    "                if match[1]>95:\n",
    "                    #add suitable matches to dictionary\n",
    "                    for nm in [match[0], name]:\n",
    "                        if nm in fn_fuzzy_pre.keys() and not marker:\n",
    "                            fn_fuzzy_pre[nm].extend([n for n in [match[0], name] if \n",
    "                                                     n != nm and n not in fn_fuzzy_pre[nm]])\n",
    "                            marker = True\n",
    "                    if not marker:\n",
    "                        if len(name) < len(match[0]):\n",
    "                            fn_fuzzy_pre[name] = [match[0]]\n",
    "                        else:\n",
    "                            fn_fuzzy_pre[match[0]] = [name]\n",
    "    #invert dictionary\n",
    "    fn_fuzzy = dict()\n",
    "    for key in fn_fuzzy_pre.keys():\n",
    "        vals = fn_fuzzy_pre[key]\n",
    "        for val in vals:\n",
    "            fn_fuzzy[val] = key\n",
    "    \n",
    "    return fn_fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate a string that contains two names into a list of two names\n",
    "def parseNames(x):\n",
    "    #replace words that don't have meaning\n",
    "    x = x.replace(\"and Co\", \"\").replace(\"and co\", \"\").replace(\"and Others\" ,\"\")\n",
    "    x = x.replace(\"and others\", \"\").replace(\"and Son\", \"\").replace(\"and Sons\", \"\")\n",
    "    x = x.replace(\"and Brothers\", \"\").strip()\n",
    "    #string preprocessing\n",
    "    namelst = x.split(\" and \")\n",
    "    namelst = [x.strip() for x in namelst if x.strip() != \"\"]\n",
    "    if len(namelst) > 1:\n",
    "        wd1len = len(namelst[0].split(\" \"))\n",
    "        wd2len = len(namelst[1].split(\" \"))\n",
    "        #add last name\n",
    "        if wd1len == 1 and wd2len != 1:\n",
    "            namelst[0] = namelst[0] + \" \" + namelst[1].split(\" \")[-1]\n",
    "    return namelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformdf(df, state):\n",
    "    #add full name columns\n",
    "    df['full name 1'] = (df['First Name'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 1'] = df['full name 1'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 2'] = (df['First Name.1'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.1'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 2'] = df['full name 2'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 3'] = (df['First Name.2'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.2'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 3'] = df['full name 3'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['debt state'] = state\n",
    "    #add dicionary to merge different full name columns into one\n",
    "    df['full name prelim'] = [genFullNameList([fname1, fname2, fname3]) \n",
    "                              for fname1, fname2, fname3 in zip(df['full name 1'],\n",
    "                                                                df['full name 2'],\n",
    "                                                                df['full name 3'])]\n",
    "    df['full name'] = df['full name prelim']\n",
    "    #do some additional preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treatde as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst])\n",
    "    #simplify state into just one column\n",
    "    if 'state1' in list(df.columns):\n",
    "        state_list = [[s for s in list(set([s1, s2, s3])) if not pd.isnull(s)]\n",
    "                      for s1, s2, s3 in zip(df['state1'], df['state2'], df['state3'])]\n",
    "        df['state']  = [state[0] if state != [] else np.nan for state in state_list]\n",
    "   \n",
    "    #fill in potentially missing states\n",
    "    missing_fullname = list(df[df['state'].apply(lambda x: pd.isnull(x))]['full name'])\n",
    "    missing_ind = list(df[df['state'].apply(lambda x: pd.isnull(x))].index)\n",
    "    replacement_states = []\n",
    "    for name in missing_fullname:\n",
    "        df_filt = df[df['full name'].apply(lambda x: x == name)] \n",
    "        if df_filt.shape[1] != 0:\n",
    "            state = list(df_filt['state'])[0]\n",
    "            replacement_states.append(state)\n",
    "        else:\n",
    "            replacement_states.append(np.nan)\n",
    "    df.loc[missing_ind, 'state'] = replacement_states\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformonecoldf(df, state):\n",
    "    #do transformdf but for when you only have one full name oclumn\n",
    "    df['full name prelim'] =  (df['First Name'] + \" \" + df['Last Name']).apply(lambda x: [x] if not pd.isnull(x) else [])\n",
    "    df['debt state'] = state\n",
    "    \n",
    "    df['full name'] = df['full name prelim']\n",
    "    #some preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treated as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst]) \n",
    "    \n",
    "    #fill in potentially missing states\n",
    "    if list(set(df['state'])) != [np.nan]:\n",
    "        missing_fullname = list(df[df['state'].apply(lambda x: pd.isnull(x))]['full name'])\n",
    "        missing_ind = list(df[df['state'].apply(lambda x: pd.isnull(x))].index)\n",
    "        replacement_states = []\n",
    "        for name in missing_fullname:\n",
    "            df_filt = df[df['full name'].apply(lambda x: x == name)] \n",
    "            if df_filt.shape[1] != 0:\n",
    "                state = list(df_filt['state'])[0]\n",
    "                replacement_states.append(state)\n",
    "            else:\n",
    "                replacement_states.append(np.nan)\n",
    "        df.loc[missing_ind, 'state'] = replacement_states\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecticut Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "CT_CD = pd.read_excel(\"Data/Post1790/CT/CT_post1790_CD_ledger.xlsx\", \n",
    "                      header = 13, usecols = 'H, I, K, N, O, X, Y, AA, AD, AE, AN, AO, AQ, AT, AU')\n",
    "CT_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents', ]\n",
    "CT_CD_agg_pre = transformdf(CT_CD, 'CT')\n",
    "CT_CD_agg = CT_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maryland Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "MD_CD = pd.read_excel(\"Data/Post1790/MD/MD_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, Z, AA, AI, AJ, AN, AO')\n",
    "MD_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "MD_CD_agg_pre = transformdf(MD_CD, 'MD')\n",
    "MD_CD_agg = MD_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([CT_CD_agg, MD_CD_agg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NC_CD = pd.read_excel(\"Data/Post1790/NC/T695_R4_NC_CD.xlsx\", \n",
    "                      header = 11, usecols = 'J, K, M, W, X, Z, AA, AC, AD ')\n",
    "NC_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_CD_agg_pre = transformonecoldf(NC_CD, 'NC')\n",
    "NC_CD_agg = NC_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Hampshire Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NH_CD = pd.read_excel(\"Data/Post1790/NH/T652_R6_New_Hampshire_CD.xlsx\", \n",
    "                      header = 10, usecols = 'I, J, L, N, O, P, Q, R, S')\n",
    "NH_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NH_CD_agg_pre = transformonecoldf(NH_CD, 'NH')\n",
    "NH_CD_agg = NH_CD_agg_pre[['full name', 'state', 'debt state',  '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NH_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new york data doesn't tell us what state people are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NY_CD = pd.read_excel(\"Data/Post1790/NY/NY_1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_CD['state'] = np.nan\n",
    "NY_CD_agg_pre = transformdf(NY_CD, 'NY')\n",
    "NY_CD_agg = NY_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NY_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# South Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_CD = pd.read_excel(\"Data/Post1790/SC/Post_1790_South_Carolina_CD.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, G, M, N, S, T, V, AB, AC, AH, AI, AK, AQ, AR')\n",
    "SC_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2',  '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "SC_CD_agg_pre = transformdf(SC_CD, 'SC')\n",
    "SC_CD_agg = SC_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([SC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pennsylvania Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "PA_CD = pd.read_excel(\"Data/Post1790/PA/PA_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AM, AO, AP')\n",
    "PA_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "PA_CD_agg_pre = transformdf(PA_CD, 'PA')\n",
    "PA_CD_agg = PA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([PA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhode Island Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_CD = pd.read_excel(\"Data/Post1790/RI/T653_Rhode_Island_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AL, AN, AO')\n",
    "RI_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "RI_CD_agg_pre = transformdf(RI_CD, 'RI')\n",
    "RI_CD_agg = RI_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([RI_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virginia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#virginia data doesn't tell us what state people are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "VA_CD = pd.read_excel(\"Data/Post1790/VA/VA_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, K, L, U, V, X, Y, AH, AI, AK, AL')\n",
    "VA_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "VA_CD['state'] = np.nan\n",
    "VA_CD_agg_pre = transformdf(VA_CD, 'VA')\n",
    "VA_CD_agg = VA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([VA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Georgia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "GA_CD = pd.read_excel(\"Data/Post1790/GA/T694_GA_Loan_Office_CD.xlsx\", \n",
    "                      header = 10, usecols = 'Q, R, T, Z, AA, AB, AC, AD, AE')\n",
    "GA_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "GA_CD_agg_pre = transformonecoldf(GA_CD, 'GA')\n",
    "GA_CD_agg = GA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([GA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no new jersey because it only has 3% stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BM</td>\n",
       "      <td>1132.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BVI</td>\n",
       "      <td>1868.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CT</td>\n",
       "      <td>1346300.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DE</td>\n",
       "      <td>12781.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FR</td>\n",
       "      <td>6820.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GA</td>\n",
       "      <td>7705.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>GB</td>\n",
       "      <td>401.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MA</td>\n",
       "      <td>132421.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>MD</td>\n",
       "      <td>1354642.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NC</td>\n",
       "      <td>54022.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NH</td>\n",
       "      <td>173675.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>NJ</td>\n",
       "      <td>43128.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>NY</td>\n",
       "      <td>25985.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PA</td>\n",
       "      <td>2250977.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>RI</td>\n",
       "      <td>687710.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>1483785.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>US</td>\n",
       "      <td>92.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>VA</td>\n",
       "      <td>27125.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>VI</td>\n",
       "      <td>3679.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>VT</td>\n",
       "      <td>5908.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state       Total\n",
       "0     BM     1132.40\n",
       "1    BVI     1868.30\n",
       "2     CT  1346300.72\n",
       "3     DE    12781.59\n",
       "4     FR     6820.77\n",
       "5     GA     7705.76\n",
       "6     GB      401.77\n",
       "7     MA   132421.46\n",
       "8     MD  1354642.06\n",
       "9     NC    54022.71\n",
       "10    NH   173675.18\n",
       "11    NJ    43128.01\n",
       "12    NY    25985.37\n",
       "13    PA  2250977.99\n",
       "14    RI   687710.78\n",
       "15    SC  1483785.86\n",
       "16    US       92.25\n",
       "17    VA    27125.15\n",
       "18    VI     3679.89\n",
       "19    VT     5908.47"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_table = cumulative_CD[['state', '6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].groupby('state').sum().reset_index()\n",
    "agg_table['Total'] = agg_table[['6p_Dollar', '6p_def_Dollar']].sum(axis = 1) + agg_table[['6p_Cents', '6p_def_Cents']].sum(axis = 1)/100\n",
    "agg_table = agg_table[['state', 'Total']]\n",
    "agg_table.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
